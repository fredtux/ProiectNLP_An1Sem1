{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "[Tutorial: Working with Hugging Face Models and Datasets](https://github.com/anyuanay/medium/blob/main/src/working_huggingface/Working_with_HuggingFace_ch4_Fine_Tuning_Pretrained_Model_for_Question_Answering.ipynb)\n",
    "\n",
    "[Fine-Tuning-for-Question-Answering-SQuAD-IndoQA](https://github.com/PrasetyoWidyantoro/Fine-Tuning-for-Question-Answering-SQuAD-IndoQA/blob/master/fine-tune-squad-dataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:36:42.724753Z",
     "iopub.status.busy": "2024-12-30T23:36:42.724428Z",
     "iopub.status.idle": "2024-12-30T23:36:47.363044Z",
     "shell.execute_reply": "2024-12-30T23:36:47.362001Z",
     "shell.execute_reply.started": "2024-12-30T23:36:42.724719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:36:47.364532Z",
     "iopub.status.busy": "2024-12-30T23:36:47.364267Z",
     "iopub.status.idle": "2024-12-30T23:37:02.319011Z",
     "shell.execute_reply": "2024-12-30T23:37:02.318090Z",
     "shell.execute_reply.started": "2024-12-30T23:36:47.364513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:02.321534Z",
     "iopub.status.busy": "2024-12-30T23:37:02.321007Z",
     "iopub.status.idle": "2024-12-30T23:37:02.325320Z",
     "shell.execute_reply": "2024-12-30T23:37:02.324458Z",
     "shell.execute_reply.started": "2024-12-30T23:37:02.321511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "kaggle = True\n",
    "\n",
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "model_short_name = \"distilbert-multilingual\"\n",
    "\n",
    "dataset_name = (\"xquad\", \"xquad.ro\")\n",
    "dataset_short_name = \"xquad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:02.326658Z",
     "iopub.status.busy": "2024-12-30T23:37:02.326391Z",
     "iopub.status.idle": "2024-12-30T23:37:03.243021Z",
     "shell.execute_reply": "2024-12-30T23:37:03.242147Z",
     "shell.execute_reply.started": "2024-12-30T23:37:02.326631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d00e2874624a92ada27653ca0b1329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c33ba736e7411aad3d3542b71c8f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ec5d283e2c4ee490a315ee06ebaee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee5c19e962a4b3487afbb1b2683007e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:03.244114Z",
     "iopub.status.busy": "2024-12-30T23:37:03.243821Z",
     "iopub.status.idle": "2024-12-30T23:37:05.010242Z",
     "shell.execute_reply": "2024-12-30T23:37:05.009614Z",
     "shell.execute_reply.started": "2024-12-30T23:37:03.244080Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5d6d3a57074428b068b80d5dc421c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a36318e5bd4c0f8f0a8961fbcb9dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/244k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5449cee34e467fa6807ce70e8a73fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 119 119\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(dataset_name[0], dataset_name[1])\n",
    "\n",
    "ds = ds['validation'].train_test_split(test_size=0.2)\n",
    "ds_train = ds['train']\n",
    "ds_test = ds['test']\n",
    "\n",
    "ds_test = ds_test.train_test_split(test_size=0.5)\n",
    "ds_val = ds_test['train']\n",
    "ds_test = ds_test['test']\n",
    "\n",
    "print(len(ds_train), len(ds_val), len(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:05.011296Z",
     "iopub.status.busy": "2024-12-30T23:37:05.011036Z",
     "iopub.status.idle": "2024-12-30T23:37:05.018939Z",
     "shell.execute_reply": "2024-12-30T23:37:05.018210Z",
     "shell.execute_reply.started": "2024-12-30T23:37:05.011263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def standardize(text: str):\n",
    "    return text\n",
    "    # return text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n",
    "\n",
    "def process_and_tokenize(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n",
    "    # Extract from the dataset and standardize where possible\n",
    "    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n",
    "    contexts = [standardize(c) for c in dataset[\"context\"]]\n",
    "    answers = dataset[\"answers\"]\n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n",
    "    offset_mapping = inputs[\"offset_mapping\"]\n",
    "    \n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "\n",
    "    for i, ofs in enumerate(offset_mapping):\n",
    "        # Get the sample\n",
    "        sample_i = sample_mapping[i]\n",
    "        \n",
    "        # Get the answer for the sample\n",
    "        answer = answers[sample_i]\n",
    "        \n",
    "        # Get the start and end character of the answer\n",
    "        start = answer[\"answer_start\"][0]\n",
    "        end = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        \n",
    "        # Get the sequence ids\n",
    "        seq_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Get the start and end token positions\n",
    "        start_context = seq_ids.index(1)\n",
    "        end_context = next(j - 1 for j in range(start_context, len(seq_ids)) if seq_ids[j] != 1)\n",
    "\n",
    "        if ofs[start_context][0] > start or ofs[end_context][1] < end: # If it's impossible\n",
    "            start_pos.append(0)\n",
    "            end_pos.append(0)\n",
    "        else: # Get and append start and end position\n",
    "            start_pos.append(next((j - 1 for j in range(start_context, end_context + 1) if ofs[j][0] > start), end_context))\n",
    "            end_pos.append(next((j + 1 for j in range(end_context, start_context - 1, -1) if ofs[j][1] < end), start_context))\n",
    "            \n",
    "            # if i < len(dataset['id']) and dataset['id'][i] == '56d6f3500d65d21400198292':\n",
    "            #     print(start_context, end_context, end_pos[-1], end_pos[-1])\n",
    "\n",
    "    inputs[\"start_positions\"] = start_pos\n",
    "    inputs[\"end_positions\"] = end_pos\n",
    "        \n",
    "    inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    inputs.pop(\"offset_mapping\")\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:05.019970Z",
     "iopub.status.busy": "2024-12-30T23:37:05.019777Z",
     "iopub.status.idle": "2024-12-30T23:37:05.568591Z",
     "shell.execute_reply": "2024-12-30T23:37:05.567627Z",
     "shell.execute_reply.started": "2024-12-30T23:37:05.019951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487289ee0fef4710b0c77aebacbe019c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/952 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n"
     ]
    }
   ],
   "source": [
    "ds_tok_train = ds_train.map(lambda x: process_and_tokenize(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_train.column_names)\n",
    " \n",
    "print(len(ds_tok_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:05.571113Z",
     "iopub.status.busy": "2024-12-30T23:37:05.570892Z",
     "iopub.status.idle": "2024-12-30T23:37:05.576676Z",
     "shell.execute_reply": "2024-12-30T23:37:05.575887Z",
     "shell.execute_reply.started": "2024-12-30T23:37:05.571093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_and_tokenize_val_test(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n",
    "    # Extract from the dataset and standardize where possible\n",
    "    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n",
    "    contexts = [standardize(c) for c in dataset[\"context\"]]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_i = sample_mapping[i]\n",
    "        example_ids.append(dataset[\"id\"][sample_i])\n",
    "\n",
    "        seq_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        \n",
    "        for j, ofs in enumerate(offset):\n",
    "            inputs['offset_mapping'][i][j] = ofs if seq_ids[j] == 1 else None\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    \n",
    "    inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:05.578030Z",
     "iopub.status.busy": "2024-12-30T23:37:05.577805Z",
     "iopub.status.idle": "2024-12-30T23:37:05.881182Z",
     "shell.execute_reply": "2024-12-30T23:37:05.880535Z",
     "shell.execute_reply.started": "2024-12-30T23:37:05.578010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e497b69dd04f6c918c6e08ad3f5561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c54f3e224245bb9cc61414e824cc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 146\n"
     ]
    }
   ],
   "source": [
    "ds_tok_val = ds_val.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_val.column_names)\n",
    "ds_tok_test = ds_test.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_test.column_names)\n",
    " \n",
    "print(len(ds_tok_val), len(ds_tok_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:05.882282Z",
     "iopub.status.busy": "2024-12-30T23:37:05.882005Z",
     "iopub.status.idle": "2024-12-30T23:37:10.762060Z",
     "shell.execute_reply": "2024-12-30T23:37:10.761114Z",
     "shell.execute_reply.started": "2024-12-30T23:37:05.882261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=2823f3119e1131ebd817336828fc32be4251eb508f18159596ccd1b3c4e772e1\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:10.763365Z",
     "iopub.status.busy": "2024-12-30T23:37:10.763018Z",
     "iopub.status.idle": "2024-12-30T23:37:13.082862Z",
     "shell.execute_reply": "2024-12-30T23:37:13.082179Z",
     "shell.execute_reply.started": "2024-12-30T23:37:10.763321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf75c6236c994c628ead8392ec314e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4aa911b7c8428ba5c155f0c5640c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64526c20012f46a08150e20745abaad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058ef95a45a34740a0c0ae78af96ef3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c11b2748a8451c8de65dc111c2e78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5f3ca14fec422aa5b6b30969814d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad_metric = evaluate.load(\"squad\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:13.083964Z",
     "iopub.status.busy": "2024-12-30T23:37:13.083673Z",
     "iopub.status.idle": "2024-12-30T23:37:13.092093Z",
     "shell.execute_reply": "2024-12-30T23:37:13.091266Z",
     "shell.execute_reply.started": "2024-12-30T23:37:13.083934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(start_logits: list, end_logits: list, tok: dict, dataset: Dataset, max_answer_length: int = 30) -> dict:\n",
    "    extracted_features = {}\n",
    "    \n",
    "    # Group extracted features by ids\n",
    "    for i, feature in enumerate(tok):\n",
    "        if feature[\"example_id\"] not in extracted_features:\n",
    "            extracted_features[feature[\"example_id\"]] = [i]\n",
    "        else:\n",
    "            extracted_features[feature[\"example_id\"]].append(i)\n",
    "    \n",
    "    golds_squad = [{\"id\": data[\"id\"], \"answers\": data[\"answers\"]} for data in dataset]\n",
    "    preds_squad = []\n",
    "    \n",
    "    golds_bleu = []\n",
    "    preds_bleu = []\n",
    "    \n",
    "    for data in tqdm(dataset):\n",
    "        answers = []\n",
    "\n",
    "        # Iterate over all the extracted features\n",
    "        for i in extracted_features[data[\"id\"]]:\n",
    "            start_logit = start_logits[i]\n",
    "            end_logit = end_logits[i]\n",
    "            offs = tok[i][\"offset_mapping\"]\n",
    "\n",
    "            # Get all combinations of start and end positions\n",
    "            for start_i in range(len(start_logit)):\n",
    "                for end_i in range(len(end_logit)):\n",
    "                    # Continue on wrong answers\n",
    "                    if offs[start_i] is None \\\n",
    "                        or offs[end_i] is None \\\n",
    "                        or end_i < start_i \\\n",
    "                        or end_i - start_i + 1 > max_answer_length:\n",
    "                        continue\n",
    "                    \n",
    "                    # Add text and score\n",
    "                    answer = {\n",
    "                        \"answer\": data[\"context\"][offs[start_i][0] : offs[end_i][1]],\n",
    "                        \"score\": start_logit[start_i] + end_logit[end_i]\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "                    \n",
    "        preds_squad.append(\n",
    "            {\"id\": data['id'], \"prediction_text\": max(answers, key=lambda x: x[\"score\"])['answer']} \n",
    "                if len(answers) > 0 else \n",
    "                {\"id\": data['id'], \"prediction_text\": \"\"}\n",
    "        )\n",
    "        \n",
    "        preds_bleu.append(\n",
    "            max(answers, key=lambda x: x[\"score\"])['answer']\n",
    "                if len(answers) > 0 else \n",
    "                \"\"\n",
    "        )\n",
    "        \n",
    "        golds_bleu.append(*[ans for ans in data[\"answers\"]['text']])\n",
    "        \n",
    "    return {\n",
    "        \"squad\": squad_metric.compute(predictions=preds_squad, references=golds_squad),\n",
    "        \"bleu\": bleu_metric.compute(predictions=preds_bleu, references=golds_bleu),\n",
    "        \"rouge\": rouge_metric.compute(predictions=preds_bleu, references=golds_bleu)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, evaluation and testing loop for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:13.093222Z",
     "iopub.status.busy": "2024-12-30T23:37:13.092966Z",
     "iopub.status.idle": "2024-12-30T23:37:13.112612Z",
     "shell.execute_reply": "2024-12-30T23:37:13.111762Z",
     "shell.execute_reply.started": "2024-12-30T23:37:13.093203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def output_metrics_to_file(metrics: dict, metric_type: str = None, lr: float = None, epoch: int = None):\n",
    "    filename = os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", f\"{model_short_name}-{dataset_short_name}-type_{metric_type}-lr_{lr}-epoch_{epoch:02}.json\" if lr is not None and epoch is not None and metric_type is not None else f\"{model_short_name}-{dataset_short_name}.json\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "        \n",
    "def save_model(trainer: Trainer, lr: float, epoch: int):\n",
    "    trainer.save_model(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))\n",
    "    \n",
    "def load_model(lr: float, epoch: int) -> AutoModelForQuestionAnswering:\n",
    "    return AutoModelForQuestionAnswering.from_pretrained(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get maximum answer length within 2 standard deviations from the mean of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:13.113583Z",
     "iopub.status.busy": "2024-12-30T23:37:13.113306Z",
     "iopub.status.idle": "2024-12-30T23:37:13.130906Z",
     "shell.execute_reply": "2024-12-30T23:37:13.130072Z",
     "shell.execute_reply.started": "2024-12-30T23:37:13.113564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# mean_answer_length = np.mean([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n",
    "# std_dev_answer_length = np.std([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n",
    "\n",
    "# two_std_devs_above = mean_answer_length + 2 * std_dev_answer_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:13.131900Z",
     "iopub.status.busy": "2024-12-30T23:37:13.131676Z",
     "iopub.status.idle": "2024-12-30T23:37:13.141872Z",
     "shell.execute_reply": "2024-12-30T23:37:13.140966Z",
     "shell.execute_reply.started": "2024-12-30T23:37:13.131882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_models_eval = None\n",
    "\n",
    "def tet_loop(lr_list: list, epochs_list: list, batch_size: int) -> None:\n",
    "    global all_models_eval\n",
    "    all_models_eval = {\"validation\": {lr:{epochs:[] for epochs in epochs_list} for lr in lr_list}, \"test\": {lr:{epochs:[] for epochs in epochs_list} for lr in lr_list}}\n",
    "    \n",
    "    for lr in lr_list:\n",
    "        for epochs in epochs_list:\n",
    "            print(f\"Training with lr={lr} and epochs={epochs}\")\n",
    "            \n",
    "            model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "            warmup_steps = int(len(ds_tok_train) / batch_size * epochs / 10)\n",
    "            \n",
    "            args = TrainingArguments(\n",
    "                output_dir=\"./results\",\n",
    "                eval_strategy=\"no\",\n",
    "                save_strategy=\"epoch\",\n",
    "                learning_rate=lr,\n",
    "                num_train_epochs=epochs,\n",
    "                weight_decay=0.01,\n",
    "                per_device_train_batch_size=batch_size, \n",
    "                report_to=\"none\",\n",
    "                save_total_limit=1,\n",
    "                warmup_steps=warmup_steps\n",
    "            )\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=args,\n",
    "                train_dataset=ds_tok_train,\n",
    "                eval_dataset=ds_tok_val,\n",
    "                tokenizer=tokenizer\n",
    "            )\n",
    "            trainer.train()\n",
    "            \n",
    "            preds, _, _ = trainer.predict(ds_tok_val)\n",
    "            start_logits, end_logits = preds\n",
    "            computed_metrics = compute_metrics(start_logits, end_logits, ds_tok_val, ds_val, 30)\n",
    "            \n",
    "            output_metrics_to_file(computed_metrics, metric_type='validation', lr=lr, epoch=epochs)\n",
    "            print(f\"Validation for lr {lr} epochs {epochs}: \")\n",
    "            # print(computed_metrics)\n",
    "            print(computed_metrics['squad'])\n",
    "            \n",
    "            all_models_eval['validation'][lr][epochs] = computed_metrics\n",
    "            \n",
    "            preds, _, _ = trainer.predict(ds_tok_test)\n",
    "            start_logits2, end_logits2 = preds\n",
    "            computed_metrics = compute_metrics(start_logits2, end_logits2, ds_tok_test, ds_test, 30)\n",
    "            \n",
    "            \n",
    "            output_metrics_to_file(computed_metrics, metric_type='test', lr=lr, epoch=epochs)\n",
    "            all_models_eval['test'][lr][epochs] = computed_metrics\n",
    "            \n",
    "\n",
    "            print(f\"Test for lr {lr} epochs {epochs}: \")\n",
    "            print(computed_metrics['squad'])\n",
    "            \n",
    "            # save_model(trainer, lr, epochs)\n",
    "            \n",
    "            # Clear CUDA cache\n",
    "            try:\n",
    "                del trainer\n",
    "                del model\n",
    "                # device = cuda.get_current_device()\n",
    "                # device.reset()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            \n",
    "            print(f\"Finished training, validating and testing with lr={lr} and epochs={epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T23:37:13.143048Z",
     "iopub.status.busy": "2024-12-30T23:37:13.142800Z",
     "iopub.status.idle": "2024-12-31T00:52:20.894732Z",
     "shell.execute_reply": "2024-12-31T00:52:20.893567Z",
     "shell.execute_reply.started": "2024-12-30T23:37:13.143018Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with lr=0.0001 and epochs=8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f2ea8b6bb847c4a4489600ccd6a30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/544 03:31, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.352700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635abc5c8b0544b5a741508a7e8c1447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epochs 8: \n",
      "{'exact_match': 23.529411764705884, 'f1': 31.71900817743365}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3928b480cd0347149953ecd2508558ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epochs 8: \n",
      "{'exact_match': 19.327731092436974, 'f1': 27.591808653285874}\n",
      "Finished training, validating and testing with lr=0.0001 and epochs=8\n",
      "Training with lr=0.0001 and epochs=16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1088' max='1088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1088/1088 06:59, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.076800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618b9eda50d64028a52109da6f0b68fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epochs 16: \n",
      "{'exact_match': 24.369747899159663, 'f1': 32.740378202563065}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaa8a958b0c4aac8e9fd73611ff6a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epochs 16: \n",
      "{'exact_match': 19.327731092436974, 'f1': 26.978224683105395}\n",
      "Finished training, validating and testing with lr=0.0001 and epochs=16\n",
      "Training with lr=0.0001 and epochs=32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2176' max='2176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2176/2176 13:55, Epoch 32/32]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.864400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd5d50dc4af4c349b059d6fc4cbab6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epochs 32: \n",
      "{'exact_match': 26.89075630252101, 'f1': 34.848407771892944}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e617e3c3d5e4504af18ceb75114075c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epochs 32: \n",
      "{'exact_match': 23.529411764705884, 'f1': 31.086912321696847}\n",
      "Finished training, validating and testing with lr=0.0001 and epochs=32\n",
      "Training with lr=0.001 and epochs=8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/544 03:31, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.298500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c1530344bd4582b0155af5834b7031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.001 epochs 8: \n",
      "{'exact_match': 2.5210084033613445, 'f1': 4.98472116119175}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806251974dc9487b8d748a49ae796a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.001 epochs 8: \n",
      "{'exact_match': 0.0, 'f1': 0.9803921568627451}\n",
      "Finished training, validating and testing with lr=0.001 and epochs=8\n",
      "Training with lr=0.001 and epochs=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1088' max='1088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1088/1088 06:59, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.962000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed4cc96ec4f410bb79db2da7da35d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.001 epochs 16: \n",
      "{'exact_match': 0.0, 'f1': 6.810144398529728}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610fa778344b4570848980c42168a355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.001 epochs 16: \n",
      "{'exact_match': 0.0, 'f1': 5.8433933521932575}\n",
      "Finished training, validating and testing with lr=0.001 and epochs=16\n",
      "Training with lr=0.001 and epochs=32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2176' max='2176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2176/2176 14:01, Epoch 32/32]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.627400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.726400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.930900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.962100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e2610196da4d0890908bfe7b3cb9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.001 epochs 32: \n",
      "{'exact_match': 0.0, 'f1': 5.843830164909083}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b621a6a8f555421189e76d41ae26b084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.001 epochs 32: \n",
      "{'exact_match': 0.0, 'f1': 3.8450380281281444}\n",
      "Finished training, validating and testing with lr=0.001 and epochs=32\n",
      "Training with lr=0.0003 and epochs=8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/544 03:31, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.453400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251400fee8274e14a55de079fac06690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0003 epochs 8: \n",
      "{'exact_match': 22.689075630252102, 'f1': 31.548747090542758}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff664d512da94f70b1a73e9a01315ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0003 epochs 8: \n",
      "{'exact_match': 13.445378151260504, 'f1': 20.00032100035283}\n",
      "Finished training, validating and testing with lr=0.0003 and epochs=8\n",
      "Training with lr=0.0003 and epochs=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1088' max='1088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1088/1088 06:59, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.165800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7633e854aa7d4613982f16b09264ae92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0003 epochs 16: \n",
      "{'exact_match': 15.126050420168067, 'f1': 21.300247371675944}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692e320f70ee4d43ad575713586e9e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0003 epochs 16: \n",
      "{'exact_match': 10.92436974789916, 'f1': 17.78402475035927}\n",
      "Finished training, validating and testing with lr=0.0003 and epochs=16\n",
      "Training with lr=0.0003 and epochs=32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2176' max='2176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2176/2176 13:58, Epoch 32/32]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.446900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f34a0f2187b43ebb03e80dc55b632df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0003 epochs 32: \n",
      "{'exact_match': 14.285714285714286, 'f1': 20.735781492084012}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065a4f6efc6b4a9d8607d7903b9e9290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0003 epochs 32: \n",
      "{'exact_match': 7.563025210084033, 'f1': 12.308927479968675}\n",
      "Finished training, validating and testing with lr=0.0003 and epochs=32\n",
      "Training with lr=0.0005 and epochs=8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 19/544 00:05 < 02:53, 3.03 it/s, Epoch 0.26/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-25b45132ee46>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtet_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5e-4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput_metrics_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c6a8687c7663>\u001b[0m in \u001b[0;36mtet_loop\u001b[0;34m(lr_list, epochs_list, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             )\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_tok_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2282\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m                 ):\n\u001b[1;32m   2286\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tet_loop(lr_list=[1e-4, 1e-3, 3e-4, 5e-4], epochs_list=[8, 16, 32], batch_size=16)\n",
    "output_metrics_to_file(all_models_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T00:52:25.458519Z",
     "iopub.status.busy": "2024-12-31T00:52:25.458130Z",
     "iopub.status.idle": "2024-12-31T00:52:25.462809Z",
     "shell.execute_reply": "2024-12-31T00:52:25.461901Z",
     "shell.execute_reply.started": "2024-12-31T00:52:25.458485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_metrics_to_file(all_models_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T00:52:28.628713Z",
     "iopub.status.busy": "2024-12-31T00:52:28.628416Z",
     "iopub.status.idle": "2024-12-31T00:52:28.790538Z",
     "shell.execute_reply": "2024-12-31T00:52:28.789450Z",
     "shell.execute_reply.started": "2024-12-31T00:52:28.628692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: results/distilbert-multilingual-xquad.json (stored 0%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.0001-epoch_08.json (deflated 53%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.0001-epoch_16.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.0001-epoch_32.json (deflated 53%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.0003-epoch_08.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.0003-epoch_16.json (deflated 53%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.0003-epoch_32.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.001-epoch_08.json (deflated 56%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.001-epoch_16.json (deflated 54%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_test-lr_0.001-epoch_32.json (deflated 54%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.0001-epoch_08.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.0001-epoch_16.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.0001-epoch_32.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.0003-epoch_08.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.0003-epoch_16.json (deflated 52%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.0003-epoch_32.json (deflated 54%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.001-epoch_08.json (deflated 55%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.001-epoch_16.json (deflated 54%)\n",
      "  adding: results/distilbert-multilingual-xquad-type_validation-lr_0.001-epoch_32.json (deflated 53%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!zip results_e4_2.zip results/*.json"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
