{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "[Tutorial: Working with Hugging Face Models and Datasets](https://github.com/anyuanay/medium/blob/main/src/working_huggingface/Working_with_HuggingFace_ch4_Fine_Tuning_Pretrained_Model_for_Question_Answering.ipynb)\n",
    "\n",
    "[Fine-Tuning-for-Question-Answering-SQuAD-IndoQA](https://github.com/PrasetyoWidyantoro/Fine-Tuning-for-Question-Answering-SQuAD-IndoQA/blob/master/fine-tune-squad-dataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:48.980173Z",
     "iopub.status.busy": "2025-01-05T05:15:48.979891Z",
     "iopub.status.idle": "2025-01-05T05:15:52.162007Z",
     "shell.execute_reply": "2025-01-05T05:15:52.160860Z",
     "shell.execute_reply.started": "2025-01-05T05:15:48.980151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: sentence-transformers in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: dill in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (0.27.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (2024.9.0)\n",
      "Requirement already satisfied: packaging in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: xxhash in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: multiprocess in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scipy in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: Pillow in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: aiohttp in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: networkx in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:52.163456Z",
     "iopub.status.busy": "2025-01-05T05:15:52.163196Z",
     "iopub.status.idle": "2025-01-05T05:15:52.167634Z",
     "shell.execute_reply": "2025-01-05T05:15:52.166807Z",
     "shell.execute_reply.started": "2025-01-05T05:15:52.163421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:52.169217Z",
     "iopub.status.busy": "2025-01-05T05:15:52.169022Z",
     "iopub.status.idle": "2025-01-05T05:15:52.185456Z",
     "shell.execute_reply": "2025-01-05T05:15:52.184648Z",
     "shell.execute_reply.started": "2025-01-05T05:15:52.169200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "kaggle = True\n",
    "\n",
    "model_name = \"racai/distilbert-base-romanian-cased\"\n",
    "model_short_name = \"distilbert-romanian\"\n",
    "\n",
    "dataset_name = (\"xquad\", \"xquad.ro\")\n",
    "dataset_short_name = \"xquad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:52.186699Z",
     "iopub.status.busy": "2025-01-05T05:15:52.186479Z",
     "iopub.status.idle": "2025-01-05T05:15:53.260227Z",
     "shell.execute_reply": "2025-01-05T05:15:53.259293Z",
     "shell.execute_reply.started": "2025-01-05T05:15:52.186680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:53.261609Z",
     "iopub.status.busy": "2025-01-05T05:15:53.261255Z",
     "iopub.status.idle": "2025-01-05T05:15:56.563249Z",
     "shell.execute_reply": "2025-01-05T05:15:56.562390Z",
     "shell.execute_reply.started": "2025-01-05T05:15:53.261575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 119 119\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(dataset_name[0], dataset_name[1])\n",
    "\n",
    "ds = ds['validation'].train_test_split(test_size=0.2)\n",
    "ds_train = ds['train']\n",
    "ds_test = ds['test']\n",
    "\n",
    "ds_test = ds_test.train_test_split(test_size=0.5)\n",
    "ds_val = ds_test['train']\n",
    "ds_test = ds_test['test']\n",
    "\n",
    "print(len(ds_train), len(ds_val), len(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:56.564599Z",
     "iopub.status.busy": "2025-01-05T05:15:56.564330Z",
     "iopub.status.idle": "2025-01-05T05:15:56.573904Z",
     "shell.execute_reply": "2025-01-05T05:15:56.573123Z",
     "shell.execute_reply.started": "2025-01-05T05:15:56.564576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def standardize(text: str):\n",
    "    return text\n",
    "    # return text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n",
    "\n",
    "def process_and_tokenize(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n",
    "    # Extract from the dataset and standardize where possible\n",
    "    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n",
    "    contexts = [standardize(c) for c in dataset[\"context\"]]\n",
    "    answers = dataset[\"answers\"]\n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n",
    "    offset_mapping = inputs[\"offset_mapping\"]\n",
    "    \n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "\n",
    "    for i, ofs in enumerate(offset_mapping):\n",
    "        # Get the sample\n",
    "        sample_i = sample_mapping[i]\n",
    "        print(answers[sample_i][\"text\"])\n",
    "        \n",
    "        # Get the answer for the sample\n",
    "        max_i = 0\n",
    "        max_len = len(answers[sample_i][\"text\"][max_i])\n",
    "        for i in range(1, len(answers[sample_i]['text'])):\n",
    "            if len(answer[\"text\"][i]) > max_len:\n",
    "                max_len = len(answers[sample_i][\"text\"][i])\n",
    "                max_i = i\n",
    "        answer = contexts[sample_i].index(answers[sample_i][\"text\"][max_i])\n",
    "\n",
    "        \n",
    "        # Get the start and end character of the answer\n",
    "        start = answer\n",
    "        end = answer + len(answers[sample_i][\"text\"][0])\n",
    "        \n",
    "        # Get the sequence ids\n",
    "        seq_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Get the start and end token positions\n",
    "        start_context = seq_ids.index(1)\n",
    "        end_context = next(j - 1 for j in range(start_context, len(seq_ids)) if seq_ids[j] != 1)\n",
    "\n",
    "        if ofs[start_context][0] > start or ofs[end_context][1] < end: # If it's impossible\n",
    "            start_pos.append(0)\n",
    "            end_pos.append(0)\n",
    "        else: # Get and append start and end position\n",
    "            start_pos.append(next((j - 1 for j in range(start_context, end_context + 1) if ofs[j][0] > start), end_context))\n",
    "            end_pos.append(next((j + 1 for j in range(end_context, start_context - 1, -1) if ofs[j][1] < end), start_context))\n",
    "            \n",
    "            # if i < len(dataset['id']) and dataset['id'][i] == '56d6f3500d65d21400198292':\n",
    "            #     print(start_context, end_context, end_pos[-1], end_pos[-1])\n",
    "\n",
    "    inputs[\"start_positions\"] = start_pos\n",
    "    inputs[\"end_positions\"] = end_pos\n",
    "        \n",
    "    inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    inputs.pop(\"offset_mapping\")\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:56.574859Z",
     "iopub.status.busy": "2025-01-05T05:15:56.574620Z",
     "iopub.status.idle": "2025-01-05T05:15:57.264225Z",
     "shell.execute_reply": "2025-01-05T05:15:57.263337Z",
     "shell.execute_reply.started": "2025-01-05T05:15:56.574840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3a2c8777104cd2b93350a10b9a8145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/952 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['China']\n",
      "['New England Patriots']\n",
      "['No Child Left Behind (Nu lăsăm niciun copil în urmă)']\n",
      "['Abu al-Rayhan al-Biruni']\n",
      "['carbonatul de sodiu și carbonatul de potasiu']\n",
      "['carbonatul de sodiu și carbonatul de potasiu']\n",
      "['Protocolul Datagramelor Utilizator']\n",
      "['Tang, Song, precum și dinastiile Khitan Liao și Jurchen Jin']\n",
      "['Tang, Song, precum și dinastiile Khitan Liao și Jurchen Jin']\n",
      "['Tesla Electric Light & Manufacturing']\n",
      "['nu pot iniția legi împotriva dorințelor Comisiei']\n",
      "['nu pot iniția legi împotriva dorințelor Comisiei']\n",
      "['nu pot iniția legi împotriva dorințelor Comisiei']\n",
      "['trăiau în sărăcie și erau rău tratați']\n",
      "['întrucât legea națională era din anul 1962, iar tratatul a intrat în vigoare în anul 1958, cererea lui Costa nu era fondată']\n",
      "['întrucât legea națională era din anul 1962, iar tratatul a intrat în vigoare în anul 1958, cererea lui Costa nu era fondată']\n",
      "['întrucât legea națională era din anul 1962, iar tratatul a intrat în vigoare în anul 1958, cererea lui Costa nu era fondată']\n",
      "['școlile alternative (charter schools)']\n",
      "['1969']\n",
      "['Protocolul de la Montreal']\n",
      "['două']\n",
      "['233']\n",
      "['James Dewar']\n",
      "['rețetele pacienților și siguranța pacientului']\n",
      "['interzicerea']\n",
      "['între 2005 și 2010']\n",
      "['aristocrația tradițională mongolă']\n",
      "['evoluția limbii și literaturii germane']\n",
      "['1895']\n",
      "['mai mult de jumătate']\n",
      "['școala de Administrare a Serviciilor Sociale']\n",
      "['1973']\n",
      "['110 mile/h']\n",
      "['110 mile/h']\n",
      "['Newton']\n",
      "['omoloage']\n",
      "['Maistru']\n",
      "['1993']\n",
      "['1964']\n",
      "['1964']\n",
      "['islamul']\n",
      "['Larry Ellison']\n",
      "['diviziune de probă']\n",
      "['ABC-DuMont']\n",
      "['calea acțiunii militare']\n",
      "['Paul Samuelson']\n",
      "['Muzeul Horniman']\n",
      "['Rețeaua de Televiziune Dumont']\n",
      "['0,3 până la 0,6 °C']\n",
      "['27 ianuarie 1967']\n",
      "['DTIME(f(n))']\n",
      "['Amazoneregenwoud']\n",
      "['Gandhi']\n",
      "['n2 + 1']\n",
      "['importanța în creștere a capitalului uman în dezvoltare']\n",
      "['Comisie și Consiliu']\n",
      "['Comisie și Consiliu']\n",
      "['Comisie și Consiliu']\n",
      "['Muhammad ibn Zakarīya Rāzi']\n",
      "['Muhammad ibn Zakarīya Rāzi']\n",
      "['comitet']\n",
      "['Charles Porter']\n",
      "['oxigen-18']\n",
      "['Omnicare, Kindred Healthcare și PharMerica']\n",
      "['miros ciudat în costume']\n",
      "['Politehnica s-a transformat în universități noi']\n",
      "['Dovedirea faptului că oricare dintre aceste clase este inegală']\n",
      "['Larry Ellison']\n",
      "['i-au luat prin surprindere pe canadieni pe 28 mai']\n",
      "['Boston']\n",
      "['Expoziției din Londra']\n",
      "['cili rigidizați']\n",
      "['711.988']\n",
      "['mijloc de deplasare']\n",
      "['taifun ostil']\n",
      "['taifun ostil']\n",
      "['multe dintre genele sale au fost pierdute sau transferate în nucleul gazdei']\n",
      "['tranziții de stare']\n",
      "['Pittsburgh Steelers']\n",
      "['Universitatea Anului în clasamentul Sunday Times']\n",
      "['Percy Shelley']\n",
      "['în vest']\n",
      "['Pearl Mackie ca și Bill']\n",
      "['10%']\n",
      "['New England Patriots']\n",
      "['Prim Ministru']\n",
      "['mai 2013']\n",
      "['forța gravitațională']\n",
      "['1968']\n",
      "['390']\n",
      "['organismele']\n",
      "['exod al albilor']\n",
      "['John Elway']\n",
      "['Construirea']\n",
      "['39']\n",
      "['cercetător nebun']\n",
      "['Hoesung Lee']\n",
      "['cili']\n",
      "['ecartamentul de 1.600 mm (5 ft 3 in)']\n",
      "['Robert Lane și Benjamin Vail']\n",
      "['imnul național']\n",
      "['separat de cea de medic']\n",
      "['Venom']\n",
      "['sărăcia, lipsa accesului la educație și instituțiile guvernamentale fără putere']\n",
      "['războaiele și „șocurile economice și politice puternice”']\n",
      "['8.646 mile pătrate']\n",
      "['geofizice']\n",
      "['primarului W. Haydon Burns']\n",
      "['patru']\n",
      "['Lady Gaga']\n",
      "['Holocenul']\n",
      "['Curtea de Justiție a Uniunii Europene cât și Înaltele Curți Naționale']\n",
      "['Curtea de Justiție a Uniunii Europene cât și Înaltele Curți Naționale']\n",
      "['Clasificarea Standard a Industriei și recentul Sistem Nord-American de Clasificare a Industriei']\n",
      "['MPEG-4']\n",
      "['nivelul existent al inegalității']\n",
      "['nouă']\n",
      "['Studenții']\n",
      "['Tesla']\n",
      "['Tratatul de la Roma din 1957 și Tratatul de la Maastricht din 1992 (în prezent: TFEU)']\n",
      "['Uraganul Dora']\n",
      "['Uraganul Dora']\n",
      "['distrusă']\n",
      "['Fortului Caroline']\n",
      "['Ordin al Conferinței Anuale a Diaconilor']\n",
      "['ADNct sau ADNcp']\n",
      "['Lucas Cranach']\n",
      "['Limbajul American al Semnelor']\n",
      "['nu încalcă drepturile celorlalți']\n",
      "['școlile guvernamentale rezervate anterior copiilor albi']\n",
      "['Fresno']\n",
      "['perechi de numere prime care diferă între ele cu o valoare de 2']\n",
      "['ABC']\n",
      "['2008']\n",
      "['2008']\n",
      "['Ghazan Han']\n",
      "['adăpost, asistență educațională, clinici medicale gratuite sau la tarife reduse, asistență legată de locuințe']\n",
      "['1756 până la semnarea tratatului de pace în 1763']\n",
      "['hoteluri din New York']\n",
      "['eroziune']\n",
      "['un client cunoscut']\n",
      "['discuri statice']\n",
      "['40.000']\n",
      "['aziluri pentru bătrâni']\n",
      "['Partidul Național']\n",
      "['Curtea Penală Internațională']\n",
      "['canalele de bază']\n",
      "['angajează farmaciști consultanți și/sau oferă servicii de consultanță']\n",
      "['35']\n",
      "['de unificare auto-consistente']\n",
      "['1944']\n",
      "['Podul John W. Weeks']\n",
      "['1321 și 1323']\n",
      "['acestea sunt judecate „greșit” de o conștiință individuală']\n",
      "['biodiversității']\n",
      "['Andrew Jackson']\n",
      "['19,3%']\n",
      "['415.000']\n",
      "['afro-americane']\n",
      "['„irațional și înapoiat”']\n",
      "['1279']\n",
      "['treilea']\n",
      "['după 1850']\n",
      "['patru']\n",
      "['teledetecția']\n",
      "['Ducele Kent-Brown']\n",
      "['Teatrul Wojciech Bogusławski']\n",
      "['prezența unui bărbat']\n",
      "['1981']\n",
      "['guru']\n",
      "['congresul și președinții']\n",
      "['de jos']\n",
      "['5,3 %']\n",
      "['Hassan al-Turabi']\n",
      "['Manning']\n",
      "['1788']\n",
      "['zonele montane']\n",
      "['Oursel']\n",
      "['5']\n",
      "['constituției coloniale din 1855']\n",
      "['receptori limfocitari variabili']\n",
      "['alte locații de pe teritoriul Scoției']\n",
      "['„aprovizionare universală”']\n",
      "['două treimi din populație']\n",
      "['16.000']\n",
      "['coerciție limitată']\n",
      "['maghiarii']\n",
      "['legitimitatea unei anumite legi']\n",
      "['1835']\n",
      "['regiunea arctică']\n",
      "['11.600 BP']\n",
      "['temperaturi mai joase pe glob']\n",
      "['Partidul Muncii']\n",
      "['forma parteneriate de afaceri cu medici sau să le dea plăți sub formă de „mită”']\n",
      "['până la 30%']\n",
      "['1.345.596']\n",
      "['cinci']\n",
      "['fiecare stat']\n",
      "['Partidul Liberal']\n",
      "['Momus']\n",
      "['războaielor']\n",
      "['The Curse of the Daleks']\n",
      "['punctul']\n",
      "['numere întregi']\n",
      "['Millingen aan de Rijn']\n",
      "['canalele prin care inegalitatea poate afecta creșterea economică']\n",
      "['Jacksonville']\n",
      "['Furtuna Tropicală Berly']\n",
      "['Furtuna Tropicală Berly']\n",
      "['blocarea porților cu lacăte']\n",
      "['Anderson']\n",
      "['clima']\n",
      "['Zone Statistice Metropolitane']\n",
      "['Antoine Lavoisier']\n",
      "['1937']\n",
      "['2016']\n",
      "['patru școli publice semi-autonome']\n",
      "['Isaac Newton']\n",
      "['P ⊆ NP ⊆ PP ⊆ PSPACE']\n",
      "['recâștige autoritatea asupra poporului său. Aceștia tindeau să îi sprijine pe francezi, cu care aveau de multă vreme relații comerciale']\n",
      "['Ciuma din Italia']\n",
      "['multicultural']\n",
      "['Autostrada Sierra']\n",
      "['dificultatea lor inerentă']\n",
      "['private tradiționale']\n",
      "['20']\n",
      "['1935']\n",
      "['Patrulaterele Principale']\n",
      "['Dynasty']\n",
      "['William Braț de Fier']\n",
      "['Annam']\n",
      "['Annam']\n",
      "['Tensorul de stres']\n",
      "['Nicholas E. Golovin']\n",
      "['Bătălia de la Dalan Balzhut']\n",
      "['peste 5100']\n",
      "['imnul național']\n",
      "['Defileul Rinului']\n",
      "['global']\n",
      "['Reconstrucția gândirii religioase în islam']\n",
      "['91%']\n",
      "['38']\n",
      "['308']\n",
      "['discipolilor săi']\n",
      "['Gărzile Roșii']\n",
      "['puterea civilă, militară și de cenzură']\n",
      "['puterea civilă, militară și de cenzură']\n",
      "['alb și negru']\n",
      "['instanță a problemei']\n",
      "['Bryan Davies']\n",
      "['374']\n",
      "['1185']\n",
      "['patru']\n",
      "['cea mai mică submulțime']\n",
      "['CBSE']\n",
      "['Rinul romantic']\n",
      "['înregistrări cu cinescop']\n",
      "['Kawann Short']\n",
      "['Kawann Short']\n",
      "['zece']\n",
      "['Guglielmo Marconi']\n",
      "['28 februarie 2008']\n",
      "['a-și putea prezenta problemele']\n",
      "['1998']\n",
      "['George Stigler']\n",
      "['susținătorii săi']\n",
      "['Shen Kuo']\n",
      "['Charles']\n",
      "['Frederick William']\n",
      "['puterii subtile']\n",
      "['negru și galben']\n",
      "['Curții Supreme ale Statelor Unite']\n",
      "['bilaterilor']\n",
      "['teoria Miasma']\n",
      "['Parlamentul Victoriei']\n",
      "['£30m']\n",
      "['1950']\n",
      "['confesiunea și dezlegarea individuală de păcate']\n",
      "['extrem de puternic']\n",
      "['șase']\n",
      "['1685']\n",
      "['îndoielnice']\n",
      "['limitarea cererii agregate']\n",
      "['orientalismului']\n",
      "['rezervate']\n",
      "['1237']\n",
      "['înainte de Primul Război Mondial']\n",
      "['serviciului militar']\n",
      "['2014']\n",
      "['cinci până la zece ani']\n",
      "['Majoritatea țărilor vestice']\n",
      "['politic']\n",
      "['un pod']\n",
      "['18%']\n",
      "['Regiunea Graniței Sudice']\n",
      "['Robert Kintner']\n",
      "['durere fizică']\n",
      "['nu fie condamnați la închisoare']\n",
      "['trei epicentre']\n",
      "['17.786.419']\n",
      "['Planet of Giants']\n",
      "['primalitate']\n",
      "['1.388']\n",
      "['proiecte de lege private']\n",
      "['educarea la scara largă']\n",
      "['An Unearthly Child']\n",
      "['ciuma este posibil să fi intrat în Europa în două valuri']\n",
      "['tentacule']\n",
      "['mai multă egalitate în distribuția venitului']\n",
      "['presupune că nu ar fi egale']\n",
      "['OpenTV']\n",
      "['PNU cât și din cea a ODM']\n",
      "['școlii Harris pentru Studiul Politicilor Publice']\n",
      "['We Love TV']\n",
      "['regenerare']\n",
      "['Qara Khitai']\n",
      "['condiții de depozitare, texte obligatorii, echipamente, etc.']\n",
      "['rareori']\n",
      "['David Banks']\n",
      "['Doctor Who and the Daleks in the Seven Keys to Doomsday']\n",
      "['Legea lui Lorentz']\n",
      "['tentilla']\n",
      "['Parlamentul Scoțian']\n",
      "['musulmană']\n",
      "['pășune pentru vite']\n",
      "['1,5 giga tone']\n",
      "['s-a realizat o conexiune interactivă gazdă-gazdă între sistemele de calculatoare cu mare putere de calcul IBM ale Universității Michigan din Anna Arbor și Universitatea de Stat Wayne']\n",
      "['Rusia']\n",
      "['Pădurea Amazoniană']\n",
      "['28.5°E']\n",
      "['Rollo']\n",
      "['dăunător']\n",
      "['Ogród Saski']\n",
      "['Satya Nadella']\n",
      "['martie']\n",
      "['turcilor Seljuk']\n",
      "['Jon Corzine']\n",
      "['Abilene']\n",
      "['reglementează meseria de farmacist și tehnician de farmacie']\n",
      "['adresă de destinație, adresă sursă, și numere de port']\n",
      "['Cracovia']\n",
      "['Orașul Manakin']\n",
      "['linia cloroplastelor algelor roșii']\n",
      "['New South Wales']\n",
      "['„aplicarea deficitară a procedurilor IPCC bine stabilite în acest caz”']\n",
      "['califat']\n",
      "['5 milioane de dolari în numerar']\n",
      "['Aeroportul Internațional Los Angeles']\n",
      "['cu reguli comune pentru cărbune și oțel']\n",
      "['independente']\n",
      "['Westminster']\n",
      "['o dată la cinci ani']\n",
      "['o dată la cinci ani']\n",
      "['o dată la cinci ani']\n",
      "['sistemului imunitar adaptiv']\n",
      "['Districtul Inferior Norfolk']\n",
      "['Kony Ealy']\n",
      "['Kony Ealy']\n",
      "['Congresului Național Indian naționalist și laic de referință din India']\n",
      "['1870 și 1939']\n",
      "['șase']\n",
      "['1.160.000']\n",
      "['1943']\n",
      "['Ministrul Federal de Interne']\n",
      "['Newton']\n",
      "['Brevetele sale']\n",
      "['Lowry Digital']\n",
      "['Novgorod și Pskov']\n",
      "['solară']\n",
      "['politici']\n",
      "['Y. p. orientalis și Y. p. medievalis']\n",
      "['forțe electromagnetice unificate']\n",
      "['două membrane lipidice dublu stratificate interioare']\n",
      "['nu']\n",
      "['John C. Messenger']\n",
      "['Doctor Who – The Ultimate Adventure']\n",
      "['English Heritage']\n",
      "['strada Konwiktorska']\n",
      "['1913']\n",
      "['63%']\n",
      "['plastom']\n",
      "['Broncos']\n",
      "['Drogo']\n",
      "['mișcarea de cumpătare']\n",
      "['șoseaua Secundară 99']\n",
      "['Ban Ki-moon']\n",
      "['Charles Richard']\n",
      "['cloroplast']\n",
      "['1972']\n",
      "['Utilitatea Banilor']\n",
      "['500.000']\n",
      "['100–150']\n",
      "['phowa și siddhi']\n",
      "['2007']\n",
      "['Nesupunerea civilă revoluționară']\n",
      "['8.8']\n",
      "['lichidul de lucru']\n",
      "['cadou']\n",
      "['2000']\n",
      "['Welfare Cash Card (Card de ajutor social)']\n",
      "['mesajul/informația originală este reasamblată în ordinea corectă, în funcție de numărul de ordine al pachetului']\n",
      "['Rinul Mijlociu']\n",
      "['existenței cloroplastului pierdut']\n",
      "['Doilea Război Mondial']\n",
      "['mult mai mari']\n",
      "['Flung to the Heedless Winds']\n",
      "['anarhiștii']\n",
      "['o colecție de protocoale de rețea creată de Digital Equipment Corporation']\n",
      "['20 la 1']\n",
      "['2012']\n",
      "['Teoria complexității computaționale']\n",
      "['Peyton Manning']\n",
      "['1,1 × 1011']\n",
      "['Liu Bingzhong și Yao Shu']\n",
      "['Liu Bingzhong și Yao Shu']\n",
      "['Embargoul']\n",
      "['proiecte de dezvoltare la scară largă']\n",
      "['Jones et al. 1998, Pollack, Huang & Shen 1998, Crowley & Lowery 2000 și Briffa 2000']\n",
      "['2015']\n",
      "['Zona Medicală și Academică Longwood']\n",
      "['școala Ortogenică Sonia Shankman']\n",
      "['Premiile Academiei Americane de Film']\n",
      "['firmele care prestează servicii în domeniul construcțiilor (spre exemplu ingineri, arhitecți) și manageri în construcții']\n",
      "['Bennie Fowler']\n",
      "['Cobb, Shepley, Rutan și Coolidge, Holabird & Roche, și alte firme de arhitectură']\n",
      "['Miller']\n",
      "['eucariotă']\n",
      "['indicatorul motorului cu aburi']\n",
      "['Brazilia']\n",
      "['100–150 specii']\n",
      "['sfârșitul Primului Război Mondial']\n",
      "['imunoglobulinele și receptorii de celule T']\n",
      "['teoriei flogisticului referitoare la combustie și coroziune']\n",
      "['12 mai 1705']\n",
      "['Kokochu']\n",
      "['Ögedei Han']\n",
      "['18 mai 1756']\n",
      "['Piața Măcelarului']\n",
      "['Adolf Galland']\n",
      "['șoseaua Secundară 41']\n",
      "['Pământul trebuie să fie mult mai bătrân decât s-a presupus anterior']\n",
      "['NBA']\n",
      "['2000']\n",
      "['Marea Expoziție din 1851']\n",
      "['eforturi speciale']\n",
      "['Ismail El Gizouli']\n",
      "['Suedia']\n",
      "['majoritate de două treimi']\n",
      "['majoritate de două treimi']\n",
      "['majoritate de două treimi']\n",
      "['Peyton Manning']\n",
      "['cameră de combustie']\n",
      "['Henry Cole']\n",
      "['1817']\n",
      "['Brookhaven']\n",
      "['1970']\n",
      "['producția de radicali liberi']\n",
      "['peste 18 ani']\n",
      "['oameni']\n",
      "['Ward']\n",
      "['Ligii Musulmane din Întreaga Indie']\n",
      "['Satyagraha']\n",
      "['antigenelor']\n",
      "['unsprezece']\n",
      "['cred în validitatea contractului social']\n",
      "['principiu local-global']\n",
      "['New Holland']\n",
      "['produsul membranei celulare a gazdei care se pliază pentru a forma o veziculă care înconjoară cianobacteria ancestrală']\n",
      "['Toyota Corona Mark II']\n",
      "['Glucocorticoizii']\n",
      "['sudul']\n",
      "['Pittsburgh Steelers']\n",
      "['Defileul Rinului']\n",
      "['11']\n",
      "['San Mateo']\n",
      "['nou costum spațial Apollo']\n",
      "['sindicate']\n",
      "['patru']\n",
      "['cunoscută în limba engleză drept Amazonia sau Jungla Amazoniană,']\n",
      "['1999']\n",
      "['Marlee Matlin']\n",
      "['necesară']\n",
      "['sfârșitul anilor 1980']\n",
      "['Aeroportul Van Nuys']\n",
      "['James Hutton']\n",
      "['Nesupunerea civilă revoluționară']\n",
      "['Despre libertatea unui creștin']\n",
      "['51,6%']\n",
      "['27-30%']\n",
      "['firme care gestionează proiecte de construcții fără a-și asuma vreo răspundere financiară directă pentru finalizarea proiectului de construire']\n",
      "['matricele adiacente']\n",
      "['Marea Britanie']\n",
      "['Parlamentul European și Consiliul Uniunii Europene']\n",
      "['Parlamentul European și Consiliul Uniunii Europene']\n",
      "['Parlamentul European și Consiliul Uniunii Europene']\n",
      "['statele membre']\n",
      "['un parteneriat cu Level 3 Communications pentru lansarea unei noi rețele naționale']\n",
      "['de-a lungul coastei']\n",
      "['iulie']\n",
      "['The Tyne and Wear Metro']\n",
      "['șoseaua Secundară 99']\n",
      "['The Hay Wain']\n",
      "['pedeapsa']\n",
      "['Națiunilor Unite']\n",
      "['Pictish']\n",
      "['Grădina Saxonă']\n",
      "['Porifera']\n",
      "['Porifera']\n",
      "['Criza energetică']\n",
      "['ramuri genetice']\n",
      "['Virgin Media']\n",
      "['islamice']\n",
      "['24']\n",
      "['24']\n",
      "['examinării învelișurilor animale fosilizate']\n",
      "['Imperialismul cultural']\n",
      "['o revistă de comerț pentru industria construcțiilor']\n",
      "['boli genetice']\n",
      "['Grupul Operativ al Metodiștilor Uniți privind Avortul și Sexualitatea']\n",
      "['trei']\n",
      "['Rinul romantic']\n",
      "['dreptul și filozofia']\n",
      "['două']\n",
      "['Hmong sau Laos']\n",
      "['Directiva Comitetului de Întreprindere']\n",
      "['Gandhi']\n",
      "['Robert Lane și Benjamin Vail']\n",
      "['120 m']\n",
      "['Hulagu Khan']\n",
      "['revizii ale regimului de medicamente']\n",
      "['Lexus']\n",
      "['reducerea sărăciei']\n",
      "['Marlee Matlin']\n",
      "['Edinburgh']\n",
      "['negocierea pedepsei']\n",
      "['pastori']\n",
      "['Trevor Martin']\n",
      "['1996']\n",
      "['soia']\n",
      "['Legea școlilor din Africa de Sud']\n",
      "['ciclului carbonului']\n",
      "['Canalul Mânecii']\n",
      "['moara de praf de pușcă Eleutherian Mills']\n",
      "['albi']\n",
      "['90%']\n",
      "['1996']\n",
      "['erau standarde deschise cu specificații publicate, iar pe lângă DEC s-au dezvoltat mai multe implementări, inclusiv una pentru Linux']\n",
      "['Franța']\n",
      "['Ibn Sina']\n",
      "['515 milioane de ani']\n",
      "['coercitive']\n",
      "['Germania']\n",
      "['graficul crosa de hochei']\n",
      "['230 milioane $']\n",
      "['1500 și 1850']\n",
      "['Nafzger']\n",
      "['Los Angeles Kings']\n",
      "['legislației farmaceutice']\n",
      "['17 secunde']\n",
      "['Tulku']\n",
      "['1774']\n",
      "['talentul său de bun animator']\n",
      "['1900']\n",
      "['bani de la sisteme bancare islamice din străinătate']\n",
      "['1940']\n",
      "['patru']\n",
      "['substanțe combustibile în ardere']\n",
      "['1760']\n",
      "['nouăsprezece']\n",
      "['Galeria T. T. Tsui']\n",
      "['notație binară']\n",
      "['Sălii Christ Church']\n",
      "['23–16']\n",
      "['Conjectura lui Brocard']\n",
      "['Legea pentru sănătate mintală (îngrijire și tratament) (Scoția) din 2003']\n",
      "['Cuaternarul']\n",
      "['ceruri']\n",
      "['Tesla Electric Light & Manufacturing']\n",
      "['1985']\n",
      "['rațional și progresiv']\n",
      "['raportul WWF']\n",
      "['nouă']\n",
      "['Parlamentul European și Consiliul Uniunii Europene']\n",
      "['Parlamentul European și Consiliul Uniunii Europene']\n",
      "['Parlamentul European și Consiliul Uniunii Europene']\n",
      "['fără echipaj uman']\n",
      "['Super Bowl XXXIII']\n",
      "['Duran Duran']\n",
      "['Un avocat']\n",
      "['extincția din Cretacic-Paleogen']\n",
      "['șase ani']\n",
      "['esențiale']\n",
      "['Ordin al Conferinței Anuale a Erudiților']\n",
      "['retorică']\n",
      "['Gottfried Semper']\n",
      "['Dallas']\n",
      "['schimbărilor climatice']\n",
      "['reguli comune pentru cărbune și oțel și ulterior pentru energia atomică']\n",
      "['Troika Design Group']\n",
      "['tentacule']\n",
      "['coloblaste']\n",
      "['macroeconomice']\n",
      "['haine de corp cu răcire cu apă']\n",
      "['situației sale financiare dezastruoase']\n",
      "['camere de oxigen']\n",
      "['ecartamentul standard de 1.435 mm (4 ft 8 1⁄2 in)']\n",
      "['M. Theo Kearney']\n",
      "['creșterii rapide a populației și a traficului în orașele de pe marginea șoselei Secundare 99, precum și a dorinței de finanțare federală']\n",
      "['James O. McKinsey']\n",
      "['autostrăzilor']\n",
      "['cererea redusă a consumatorilor']\n",
      "['cloroplast derivat din algele verzi']\n",
      "['confecționarea']\n",
      "['termeni de presiune']\n",
      "['a urcat']\n",
      "['numărătoare inversă la lansare']\n",
      "['cască cu vizieră']\n",
      "['Asociației Medicale Americane']\n",
      "['Ergänzungsschulen']\n",
      "['68.511']\n",
      "['Brazilia']\n",
      "['relativitatea generală']\n",
      "['3,62']\n",
      "['John Wesley']\n",
      "['diplomă de licență']\n",
      "['puterea deținută de fiecare partid în parlament']\n",
      "['universitate și academia militară']\n",
      "['America de Nord']\n",
      "['carcasa turbinei']\n",
      "['la un nivel profund']\n",
      "['1288']\n",
      "['1288']\n",
      "['1936']\n",
      "['ABC on Demand']\n",
      "['britanici']\n",
      "['22.338.618']\n",
      "['sute']\n",
      "['companii complet diferite']\n",
      "['Edsen Khoroo']\n",
      "['crichet, raliu, fotbal, rugby, și box']\n",
      "['două']\n",
      "['două']\n",
      "['Vicepreședintele Executiv pentru Operațiuni de Fotbal și Managerul General']\n",
      "['până în al doilea sfert al secolului 19']\n",
      "['Frederick W. Mote']\n",
      "['lucruri care reprezintă o chestiune de obișnuință sau așteptări']\n",
      "['E.I. du Pont']\n",
      "['India liberă']\n",
      "['vest']\n",
      "['Statele Unite']\n",
      "['limita de deformare a oțelului inoxidabil']\n",
      "['Ford']\n",
      "['patru']\n",
      "['Dudley Simpson']\n",
      "['Energiprojekt AB']\n",
      "['regimuri islamice non-liberale']\n",
      "['timpurie']\n",
      "['Afranji']\n",
      "['comportamentale și demografice']\n",
      "['Dolby Digital']\n",
      "['1990s']\n",
      "['medicamente citotoxice sau imunosupresive']\n",
      "['variație antigenică']\n",
      "['sume conectate a unor noduri prime']\n",
      "['deoarece, în mod arbitrar, se pot include multe exemple cu 1 în orice factorizare']\n",
      "['Aristotel']\n",
      "['forțelor de poliție și armate']\n",
      "['de zece ori mai mult decât greutatea proprie']\n",
      "['1901']\n",
      "['Ward']\n",
      "['Amazonul reprezintă peste jumătate din pădurile tropicale rămase ale planetei']\n",
      "['evenimente din viața lui']\n",
      "['asfixiat']\n",
      "['contract de „proiectare-execuție”']\n",
      "['trei']\n",
      "['agricultură']\n",
      "['1986']\n",
      "['1263']\n",
      "['suc nefermentat de struguri']\n",
      "['tablou']\n",
      "['3,07']\n",
      "['Scara Saffir-Simpson']\n",
      "['Scara Saffir-Simpson']\n",
      "['Lady Gaga']\n",
      "['cosmologiei aristoteliene']\n",
      "['7 până la 10 procente']\n",
      "['Pedro Menéndez de Avilés']\n",
      "['a instalat sisteme de iluminat pe bază de arc electric concepute de Tesla']\n",
      "['2018']\n",
      "['octombrie 2016']\n",
      "['Comisia']\n",
      "['Comisia']\n",
      "['Comisia']\n",
      "['vest']\n",
      "['13.000 BP']\n",
      "['4:51']\n",
      "['Baiju']\n",
      "['devine mai mică']\n",
      "['râului St. Johns']\n",
      "['Rolul principal']\n",
      "['șapte']\n",
      "['în incinta farmaciei/preparând medicamente']\n",
      "['peste jumătate']\n",
      "['Jacques Lefevre']\n",
      "['Teorema fundamentală a aritmeticii']\n",
      "['corupției în sectorul public']\n",
      "['Frontul Național Islamic']\n",
      "['Virgin Media']\n",
      "['565 °C']\n",
      "['HIV']\n",
      "['38']\n",
      "['Satyagraha']\n",
      "['aprilie 1991']\n",
      "['o combinație de antrax și alte pandemii']\n",
      "['cinci milioane']\n",
      "['alegerii Partidului Laburist din Regatul Unit la guvernare']\n",
      "['funcționarea unui sistem']\n",
      "['New England Patriots']\n",
      "['136']\n",
      "['136']\n",
      "['refuzul de a plăti taxe']\n",
      "['de acum 66 de milioane de ani']\n",
      "['pentru coordonarea consecințelor embargo-ului']\n",
      "['Bătălia de la Jumonville Glen']\n",
      "['Jean Cauvin']\n",
      "['nonviolent']\n",
      "['înlăturarea fundamentului său economic']\n",
      "['Astra 2A']\n",
      "['setul de triplete']\n",
      "['„Suntem cerșetori”']\n",
      "['BSkyB']\n",
      "['metotrexatul sau azatioprina']\n",
      "['„O mașină care să pună capăt războiului”']\n",
      "['22.000']\n",
      "['Persia']\n",
      "['un fel de „otrăvire a sângelui']\n",
      "['Alpha Repertory Television Service (ARTS)']\n",
      "['instituțiile comprehensive ale Marelui Yuan']\n",
      "['39']\n",
      "['12%']\n",
      "['aristocrație']\n",
      "['zece milioane']\n",
      "['șapte ani']\n",
      "['protest nonviolent']\n",
      "['6 octombrie 1973']\n",
      "['specialităților care erau anterior separate']\n",
      "['Marea Japoniei']\n",
      "['John Elway']\n",
      "['Rin-Meuse']\n",
      "['distrugerea pădurii']\n",
      "['1530']\n",
      "['construirea de clădiri, construcții civile și industriale, și contractanți comerciali de specialitate']\n",
      "['principalelor mărci de autoturisme']\n",
      "['Aeroportul Internațional San Diego']\n",
      "['Curții Supreme a Statelor Unite']\n",
      "['formele nedrepte de autoritate']\n",
      "['ascensiunea lui Adolf Hitler la putere']\n",
      "['anului 1521']\n",
      "['Curții Europene a Drepturilor Omului']\n",
      "['între P și PSPACE']\n",
      "['profesionale']\n",
      "['eșuat']\n",
      "['Rev. Paul T. Stallsworth']\n",
      "['1851']\n",
      "['515 milioane de ani']\n",
      "['militantă jihadistă Wahhabi/Salafi extremistă']\n",
      "['Cel de-al Unsprezecelea Doctor']\n",
      "['Rețeaua Internet2']\n",
      "['monofiletice']\n",
      "['se credea că dezavantajează candidații cu venituri reduse și minoritățile subreprezentate']\n",
      "['Zona de Vest']\n",
      "['oxigen 100%']\n",
      "['districte sau powiat']\n",
      "['legea UE']\n",
      "['legea UE']\n",
      "['Dongshan Dafo Dian']\n",
      "['55,1%']\n",
      "['Josh Norman']\n",
      "['o platformă de satelit']\n",
      "['condamnat drept idolatrie']\n",
      "['recunoașterea']\n",
      "['1520']\n",
      "['Charles Darwin']\n",
      "['Ein neues Lied wir heben an']\n",
      "['de două ori']\n",
      "[\"Mănăstirea Kumbum sau Ta'er Shi de lângă Xining\"]\n",
      "['sindicate']\n",
      "['Generalul-Maior James Abercrombie']\n",
      "['139']\n",
      "['afro-americani']\n",
      "['2014']\n",
      "['transportul, canalizarea, deșeurile periculoase și apa']\n",
      "['încălzire suplimentară a suprafeței Pământului']\n",
      "['Președintele Statelor Unite Barack Obama']\n",
      "['o dată la cinci ani']\n",
      "['o dată la cinci ani']\n",
      "['o dată la cinci ani']\n",
      "['cerințele privind codul zonal și de construire']\n",
      "['Louis al XIV-lea']\n",
      "['armatei germane']\n",
      "['pe suprafața pământului']\n",
      "['1943']\n",
      "['Abu al-Qasim al-Zahrawi']\n",
      "['Abu al-Qasim al-Zahrawi']\n",
      "['nu există o cameră pentru revizuiri']\n",
      "['2005']\n",
      "['1997']\n",
      "['Delta Rinului']\n",
      "['2010']\n",
      "['folk rock']\n",
      "['Polonia Varșovia']\n",
      "['Allston']\n",
      "['mai puternic']\n",
      "['Pilot Modul Lunar']\n",
      "['LA Galaxy']\n",
      "['Joseph Shea']\n",
      "['cresc semnificativ concentrațiile atmosferice']\n",
      "['Trypanosoma brucei']\n",
      "['aproximativ un milion de ani']\n",
      "['1950']\n",
      "['aerul condiționat']\n",
      "['statele și guvernele']\n",
      "['forța electrostatică']\n",
      "['electric']\n",
      "['două']\n",
      "['tifosul, variola și infecțiile respiratorii']\n",
      "['25']\n",
      "['30 °C']\n",
      "['Bătălia de la Bạch Đặng']\n",
      "['Bătălia de la Bạch Đặng']\n",
      "['1908']\n",
      "['filosofia yin-yang și wuxing']\n",
      "['bacteriile anaerobe']\n",
      "['cili rigidizați']\n",
      "['terestră digitală']\n",
      "['infecții recurente, amenințătoare de viață']\n",
      "['poporului Han, Khitan, Jurchen, mongol, și pe budiștii tibetani']\n",
      "['poporului Han, Khitan, Jurchen, mongol, și pe budiștii tibetani']\n",
      "['8 februarie 2007']\n",
      "['2020']\n",
      "['Lady Gaga']\n",
      "['timp']\n",
      "['mijlocul secolului 18']\n",
      "['după 1279']\n",
      "['după 1279']\n",
      "['publicații în limba germană']\n",
      "['Două diferențe fundamentale includeau împărțirea funcțiilor și a sarcinilor între gazdele de la marginea rețelei și cele din centrul rețelei']\n",
      "['deoarece erau metodici și foarte amănunțiți când venea vorba de studiul Bibliei']\n",
      "['16.000']\n",
      "['două']\n",
      "['dovezi']\n",
      "['perioada de mijloc a Cambrianului']\n",
      "['2003']\n",
      "['tentacule']\n",
      "['dificultate']\n",
      "['„Variații ale stratului de zăpadă și gheață în trecut și în prezent la nivel global și regional”']\n",
      "['patru']\n",
      "['patru']\n",
      "['1754']\n",
      "['unitatea SI pentru densitatea de fluxul magnetic']\n",
      "['Merkit']\n",
      "['24']\n",
      "['valoarea absolută']\n",
      "['Harrods']\n",
      "['orice obiect se poate descompune, în general în mod unic, între componentele sale prime']\n",
      "['mare parte din secolul al nouăsprezecelea']\n",
      "['Fort Caroline']\n",
      "['un număr de calificări']\n",
      "['China, Japonia și Coreea']\n",
      "['30']\n",
      "['una dintre cele mai obișnuite']\n",
      "['de zece ori mai mult decât greutatea proprie']\n",
      "['340 de mile']\n",
      "['majoritatea electoratului']\n",
      "['Virginia']\n",
      "['Thomas Piketty']\n",
      "['Legea Constituției Victoriene din 1855']\n",
      "['religioase']\n",
      "['mamelucii din Egipt']\n",
      "['Al-Muwaffaq']\n",
      "['Al-Muwaffaq']\n",
      "['Faptul că ciuma a fost provocată de aerul rău']\n",
      "['1349']\n",
      "['17']\n",
      "['Kurt Coleman']\n",
      "['Kurt Coleman']\n",
      "['tentilla']\n",
      "[', cu scopul de a contribui la dezvoltarea educațională și economică a statului']\n",
      "['1950']\n",
      "['gestionare a departamentului farmaceutic și a zonelor de specialitate din practica farmaceutică']\n",
      "['Principiul succesiunii faunelor']\n",
      "['al Doilea Război Mondial']\n",
      "['nenaturală']\n",
      "['carbonului conținut în vegetație']\n",
      "['Generalul-Maior Louis-Joseph de Montcalm']\n",
      "['1962']\n",
      "['linia cloroplastelor verzi']\n",
      "['ipoteza curbei Kuznets']\n",
      "['587.000']\n",
      "['când sistemul imunitar este mai puțin activ decât normal']\n",
      "['Economistul']\n",
      "['100–150']\n",
      "['12-lea']\n",
      "['Quest']\n",
      "['Africa de Nord și Vest']\n",
      "['registrele sondelor forate']\n",
      "['o formă de antrax']\n",
      "['Edictul din Fontainebleau']\n",
      "['metropolitană internațională']\n",
      "['40']\n",
      "['prin portul Marseille în jurul lunii noiembrie 1347']\n",
      "['creșterea numărului de așezări și a defrișărilor']\n",
      "['37,6 miliarde de dolari']\n",
      "['celulele citotoxice Natural Killer și CTLs (limfocite T citotoxice)']\n",
      "['finanțeze']\n",
      "['chișcarul și mixina']\n",
      "['Chivas']\n",
      "['Testul de primalitate Miller–Rabin']\n",
      "['1654']\n",
      "['Nesupunerea civilă nerevoluționară']\n",
      "['unitatea SI pentru densitatea de fluxul magnetic']\n",
      "['mai bune']\n",
      "['Muzeul Producătorilor']\n",
      "['1891']\n",
      "['solidaritate']\n",
      "['tentacule']\n",
      "['botanică și chimie']\n",
      "['botanică și chimie']\n",
      "['Lothar de Maizière']\n",
      "['Michael E. Mann, Raymond S. Bradley, și Malcolm K. Hughes']\n",
      "['11']\n",
      "['ciclosporina']\n",
      "['Sydney']\n",
      "['număr compus']\n",
      "[', fără a se distruge legitimitatea istorică']\n",
      "['melatoninei']\n",
      "['Broncos']\n",
      "['roman']\n",
      "['Mickey Smith (Noel Clarke) și Jack Harkness (John Barrowman)']\n",
      "['Africii']\n",
      "['fie judecați de un judecător']\n",
      "['global']\n",
      "['un consorțiu de rețele de calculatoare, nu pentru profit, din Statele Unite condus de membri ai comunităților de cercetare și educație, industrie, și guvern']\n",
      "['sistem formal']\n",
      "['Subdiviziunea izolată']\n",
      "['32,9%']\n",
      "['Grissom, White, și Chaffee']\n",
      "['incendiu electric']\n",
      "['Josh Norman']\n",
      "['școlile de Laborator ale Universității din Chicago']\n",
      "['Paleoclimatologii']\n",
      "['feminin']\n",
      "['palmieri înalți']\n",
      "['2005']\n",
      "['el însuși']\n",
      "['s-au alăturat în cele din urmă altor secte protestante']\n",
      "['două echipe de cercetători japonezi']\n",
      "['tiroida Hashimoto']\n",
      "['sistemul său umoral']\n",
      "['1857']\n",
      "['să renască']\n",
      "['Milton Friedman']\n",
      "['2011 și 2012']\n",
      "['Ming și Qing']\n",
      "['Gandhi']\n",
      "['meduză pieptene']\n",
      "['1186']\n",
      "['cortizolul și catecolaminele']\n",
      "['bibliei']\n",
      "['geografie imaginativă']\n",
      "['38']\n",
      "['1943']\n",
      "['nu se poate scrie drept suma a două noduri netriviale']\n",
      "['tripartită']\n",
      "['tripartită']\n",
      "['1886']\n",
      "['20–18']\n",
      "['1970']\n",
      "['John Elway']\n",
      "['programe de calculator']\n",
      "['Smith and Jones']\n",
      "['automatizare']\n",
      "['Percy Shelley']\n",
      "['îngrijorare']\n",
      "['1946']\n",
      "['trei']\n",
      "['castele și podgorii']\n",
      "['comprimă cea mai recentă eră']\n",
      "['118']\n",
      "['arbore motor']\n",
      "['Liga Engleză de Fotbal Premier League']\n",
      "['Broncos']\n",
      "['îngreunează funcționarea unui sistem']\n",
      "['Iisus Interpretul']\n",
      "['de la Noua Scoție și Newfoundland în nord, până la Georgia în sud']\n",
      "['1960 și 1970']\n",
      "['doar farmaciștii']\n",
      "['Jean Ribault']\n",
      "['Lume și Imagini']\n",
      "['Partidul Verde']\n",
      "['Partidul Muncii din Australia (ALP)']\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "ds_tok_train = ds_train.map(lambda x: process_and_tokenize(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_train.column_names)\n",
    " \n",
    "print(len(ds_tok_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:57.266564Z",
     "iopub.status.busy": "2025-01-05T05:15:57.266287Z",
     "iopub.status.idle": "2025-01-05T05:15:57.272195Z",
     "shell.execute_reply": "2025-01-05T05:15:57.271309Z",
     "shell.execute_reply.started": "2025-01-05T05:15:57.266538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_and_tokenize_val_test(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n",
    "    # Extract from the dataset and standardize where possible\n",
    "    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n",
    "    contexts = [standardize(c) for c in dataset[\"context\"]]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_i = sample_mapping[i]\n",
    "        example_ids.append(dataset[\"id\"][sample_i])\n",
    "\n",
    "        seq_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        \n",
    "        for j, ofs in enumerate(offset):\n",
    "            inputs['offset_mapping'][i][j] = ofs if seq_ids[j] == 1 else None\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    \n",
    "    inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:57.273650Z",
     "iopub.status.busy": "2025-01-05T05:15:57.273382Z",
     "iopub.status.idle": "2025-01-05T05:15:57.536540Z",
     "shell.execute_reply": "2025-01-05T05:15:57.535644Z",
     "shell.execute_reply.started": "2025-01-05T05:15:57.273629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9395ae949bbe47f5b43e09695fb438d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f3fa1cf0064d4cac96dee09a17a166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 126\n"
     ]
    }
   ],
   "source": [
    "ds_tok_val = ds_val.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_val.column_names)\n",
    "ds_tok_test = ds_test.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_test.column_names)\n",
    " \n",
    "print(len(ds_tok_val), len(ds_tok_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:15:57.537794Z",
     "iopub.status.busy": "2025-01-05T05:15:57.537504Z",
     "iopub.status.idle": "2025-01-05T05:16:02.473177Z",
     "shell.execute_reply": "2025-01-05T05:16:02.472224Z",
     "shell.execute_reply.started": "2025-01-05T05:15:57.537770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: joblib in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: click in /home/tux/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:16:02.474626Z",
     "iopub.status.busy": "2025-01-05T05:16:02.474277Z",
     "iopub.status.idle": "2025-01-05T05:16:05.729768Z",
     "shell.execute_reply": "2025-01-05T05:16:05.729039Z",
     "shell.execute_reply.started": "2025-01-05T05:16:02.474600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "squad_metric = evaluate.load(\"squad\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:16:05.730812Z",
     "iopub.status.busy": "2025-01-05T05:16:05.730590Z",
     "iopub.status.idle": "2025-01-05T05:16:05.740470Z",
     "shell.execute_reply": "2025-01-05T05:16:05.739677Z",
     "shell.execute_reply.started": "2025-01-05T05:16:05.730793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 3.95 GiB of which 672.00 MiB is free. Process 2478694 has 3.24 GiB memory in use. Including non-PyTorch memory, this process has 44.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(start_logits: \u001b[38;5;28mlist\u001b[39m, end_logits: \u001b[38;5;28mlist\u001b[39m, tok: \u001b[38;5;28mdict\u001b[39m, dataset: Dataset, max_answer_length: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m, eval_answer: SentenceTransformer \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBlackKakapo/stsb-xlm-r-multilingual-ro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m      2\u001b[0m     extracted_features \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Group extracted features by ids\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:347\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m~/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Master/An1/NLP/ProiectGit/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 3.95 GiB of which 672.00 MiB is free. Process 2478694 has 3.24 GiB memory in use. Including non-PyTorch memory, this process has 44.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "def compute_metrics(start_logits: list, end_logits: list, tok: dict, dataset: Dataset, max_answer_length: int = 30, eval_answer: SentenceTransformer = SentenceTransformer(\"BlackKakapo/stsb-xlm-r-multilingual-ro\")) -> dict:\n",
    "    extracted_features = {}\n",
    "    \n",
    "    # Group extracted features by ids\n",
    "    for i, feature in enumerate(tok):\n",
    "        if feature[\"example_id\"] not in extracted_features:\n",
    "            extracted_features[feature[\"example_id\"]] = [i]\n",
    "        else:\n",
    "            extracted_features[feature[\"example_id\"]].append(i)\n",
    "    \n",
    "    golds_squad = [{\"id\": data[\"id\"], \"answers\": data[\"answers\"]} for data in dataset]\n",
    "    preds_squad = []\n",
    "    \n",
    "    golds_bleu = []\n",
    "    preds_bleu = []\n",
    "    \n",
    "    for data in tqdm(dataset):\n",
    "        answers = []\n",
    "\n",
    "        # Iterate over all the extracted features\n",
    "        for i in extracted_features[data[\"id\"]]:\n",
    "            start_logit = start_logits[i]\n",
    "            end_logit = end_logits[i]\n",
    "            offs = tok[i][\"offset_mapping\"]\n",
    "\n",
    "            # Get all combinations of start and end positions\n",
    "            for start_i in range(len(start_logit)):\n",
    "                for end_i in range(len(end_logit)):\n",
    "                    # Continue on wrong answers\n",
    "                    if offs[start_i] is None \\\n",
    "                        or offs[end_i] is None \\\n",
    "                        or end_i < start_i \\\n",
    "                        or end_i - start_i + 1 > max_answer_length:\n",
    "                        continue\n",
    "                    \n",
    "                    # Add text and score\n",
    "                    answer = {\n",
    "                        \"answer\": data[\"context\"][offs[start_i][0] : offs[end_i][1]],\n",
    "                        \"score\": start_logit[start_i] + end_logit[end_i]\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "                    \n",
    "        preds_squad.append(\n",
    "            {\"id\": data['id'], \"prediction_text\": max(answers, key=lambda x: x[\"score\"])['answer']} \n",
    "                if len(answers) > 0 else \n",
    "                {\"id\": data['id'], \"prediction_text\": \"\"}\n",
    "        )\n",
    "        \n",
    "        preds_bleu.append(\n",
    "            max(answers, key=lambda x: x[\"score\"])['answer']\n",
    "                if len(answers) > 0 else \n",
    "                \"\"\n",
    "        )\n",
    "        \n",
    "        max_i = 0\n",
    "        max_len = len(data[\"answers\"][\"text\"][max_i])\n",
    "        for i in range(1, len(data[\"answers\"]['text'])):\n",
    "            if len(data[\"answers\"][\"text\"][i]) > max_len:\n",
    "                max_len = len(data[\"answers\"][\"text\"][i])\n",
    "                max_i = i\n",
    "        \n",
    "        golds_bleu.append(data[\"answers\"]['text'][max_i])\n",
    "        \n",
    "    return {\n",
    "        \"squad\": squad_metric.compute(predictions=preds_squad, references=golds_squad),\n",
    "        \"bleu\": bleu_metric.compute(predictions=preds_bleu, references=golds_bleu),\n",
    "        \"rouge\": rouge_metric.compute(predictions=preds_bleu, references=golds_bleu),\n",
    "        \"semantic_similarity\": util.pytorch_cos_sim(eval_answer.encode(preds_bleu, convert_to_tensor=True), eval_answer.encode(golds_bleu, convert_to_tensor=True)).mean().item() * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, evaluation and testing loop for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:16:05.741607Z",
     "iopub.status.busy": "2025-01-05T05:16:05.741274Z",
     "iopub.status.idle": "2025-01-05T05:16:05.764686Z",
     "shell.execute_reply": "2025-01-05T05:16:05.763861Z",
     "shell.execute_reply.started": "2025-01-05T05:16:05.741577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def output_metrics_to_file(metrics: dict, metric_type: str = None, lr: float = None, epoch: int = None):\n",
    "    filename = os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", f\"{model_short_name}-{dataset_short_name}-type_{metric_type}-lr_{lr}-epoch_{epoch:02}.json\" if lr is not None and epoch is not None and metric_type is not None else f\"{model_short_name}-{dataset_short_name}.json\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "        \n",
    "def save_model(trainer: Trainer, lr: float, epoch: int):\n",
    "    trainer.save_model(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))\n",
    "    \n",
    "def load_model(lr: float, epoch: int) -> AutoModelForQuestionAnswering:\n",
    "    return AutoModelForQuestionAnswering.from_pretrained(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get maximum answer length within 2 standard deviations from the mean of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:16:05.765619Z",
     "iopub.status.busy": "2025-01-05T05:16:05.765388Z",
     "iopub.status.idle": "2025-01-05T05:16:05.780139Z",
     "shell.execute_reply": "2025-01-05T05:16:05.779319Z",
     "shell.execute_reply.started": "2025-01-05T05:16:05.765600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# mean_answer_length = np.mean([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n",
    "# std_dev_answer_length = np.std([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n",
    "\n",
    "# two_std_devs_above = mean_answer_length + 2 * std_dev_answer_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:16:05.781395Z",
     "iopub.status.busy": "2025-01-05T05:16:05.781101Z",
     "iopub.status.idle": "2025-01-05T05:16:05.794555Z",
     "shell.execute_reply": "2025-01-05T05:16:05.793937Z",
     "shell.execute_reply.started": "2025-01-05T05:16:05.781367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_models_eval = None\n",
    "\n",
    "def tet_loop(lr_list: list, epochs: int, batch_size: int) -> None:\n",
    "    global all_models_eval\n",
    "    all_models_eval = {\"validation\": {lr:{epoch:[] for epoch in range(1, epochs + 1)} for lr in lr_list}, \"test\": {lr:{epoch:[] for epoch in range(1, epochs + 1)} for lr in lr_list}}\n",
    "    \n",
    "    eval_answer = SentenceTransformer(\"BlackKakapo/stsb-xlm-r-multilingual-ro\")\n",
    "    \n",
    "    for lr in lr_list:\n",
    "        model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "        warmup_steps = int(len(ds_tok_train) / batch_size * 1 / 10)\n",
    "        args = TrainingArguments(\n",
    "                output_dir=\"./results\",\n",
    "                eval_strategy=\"no\",\n",
    "                save_strategy=\"epoch\",\n",
    "                learning_rate=lr,\n",
    "                num_train_epochs=1,\n",
    "                weight_decay=0.01,\n",
    "                per_device_train_batch_size=batch_size, \n",
    "                report_to=\"none\",\n",
    "                save_total_limit=1,\n",
    "                warmup_steps=warmup_steps\n",
    "            )\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=ds_tok_train,\n",
    "            eval_dataset=ds_tok_val,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            print(f\"Training with lr={lr} and epoch={epoch}\")\n",
    "            \n",
    "            trainer.train()\n",
    "            \n",
    "            preds = trainer.predict(ds_tok_val)\n",
    "            start_logits, end_logits = preds[0][0], preds[0][1]\n",
    "            computed_metrics = compute_metrics(start_logits, end_logits, ds_tok_val, ds_val, 30, eval_answer)\n",
    "            \n",
    "            # output_metrics_to_file(computed_metrics, metric_type='validation', lr=lr, epoch=epoch)\n",
    "            print(f\"Validation for lr {lr} epoch {epoch}: \")\n",
    "            # print(computed_metrics)\n",
    "            print(computed_metrics['squad'])\n",
    "            print(computed_metrics['semantic_similarity'])\n",
    "            \n",
    "            all_models_eval['validation'][lr][epoch] = computed_metrics\n",
    "            \n",
    "            preds = trainer.predict(ds_tok_test)\n",
    "            start_logits2, end_logits2 = preds[0][0], preds[0][1]\n",
    "            computed_metrics = compute_metrics(start_logits2, end_logits2, ds_tok_test, ds_test, 30, eval_answer)\n",
    "            \n",
    "            \n",
    "            # output_metrics_to_file(computed_metrics, metric_type='test', lr=lr, epoch=epoch)\n",
    "            all_models_eval['test'][lr][epoch] = computed_metrics\n",
    "            \n",
    "\n",
    "            print(f\"Test for lr {lr} epoch {epoch}: \")\n",
    "            print(computed_metrics['squad'])\n",
    "            print(computed_metrics['semantic_similarity'])\n",
    "            \n",
    "            # save_model(trainer, lr, epoch)\n",
    "            \n",
    "        try:\n",
    "            del trainer\n",
    "            del model\n",
    "            # device = cuda.get_current_device()\n",
    "            # device.reset()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            print(f\"Finished training, validating and testing with lr={lr} and epochs={epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T05:16:05.795664Z",
     "iopub.status.busy": "2025-01-05T05:16:05.795375Z",
     "iopub.status.idle": "2025-01-05T06:11:56.446500Z",
     "shell.execute_reply": "2025-01-05T06:11:56.445705Z",
     "shell.execute_reply.started": "2025-01-05T05:16:05.795637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tet_loop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtet_loop\u001b[49m(lr_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1e-4\u001b[39m], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tet_loop' is not defined"
     ]
    }
   ],
   "source": [
    "tet_loop(lr_list=[1e-4], epochs=2, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T06:11:56.447967Z",
     "iopub.status.busy": "2025-01-05T06:11:56.447728Z",
     "iopub.status.idle": "2025-01-05T06:11:56.462963Z",
     "shell.execute_reply": "2025-01-05T06:11:56.462297Z",
     "shell.execute_reply.started": "2025-01-05T06:11:56.447946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_metrics_to_file(all_models_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T06:11:56.463849Z",
     "iopub.status.busy": "2025-01-05T06:11:56.463646Z",
     "iopub.status.idle": "2025-01-05T06:11:56.647961Z",
     "shell.execute_reply": "2025-01-05T06:11:56.646831Z",
     "shell.execute_reply.started": "2025-01-05T06:11:56.463825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: results/distilbert-romanian-xquad.json (deflated 86%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_01.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_02.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_03.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_04.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_05.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_06.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_07.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_08.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_09.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_10.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_11.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_12.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_13.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_14.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_15.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_16.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_17.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_18.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_19.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_20.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_21.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_22.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_23.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_24.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_25.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_26.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_27.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_28.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_29.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_30.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_31.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_32.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_01.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_02.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_03.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_04.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_05.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_06.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_07.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_08.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_09.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_10.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_11.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_12.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_13.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_14.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_15.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_16.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_17.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_18.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_19.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_20.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_21.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_22.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_23.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_24.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_25.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_26.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_27.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_28.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_29.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_30.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_31.json (deflated 55%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_32.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_01.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_02.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_03.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_04.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_05.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_06.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_07.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_08.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_09.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_10.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_11.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_12.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_13.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_14.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_15.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_16.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_17.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_18.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_19.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_20.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_21.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_22.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_23.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_24.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_25.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_26.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_27.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_28.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_29.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_30.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_31.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_32.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_01.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_02.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_03.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_04.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_05.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_06.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_07.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_08.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_09.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_10.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_11.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_12.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_13.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_14.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_15.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_16.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_17.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_18.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_19.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_20.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_21.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_22.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_23.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_24.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_25.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_26.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_27.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_28.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_29.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_30.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_31.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_32.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_01.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_02.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_03.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_04.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_05.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_06.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_07.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_08.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_09.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_10.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_11.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_12.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_13.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_14.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_15.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_16.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_17.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_18.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_19.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_20.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_21.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_22.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_23.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_24.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_25.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_26.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_27.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_28.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_29.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_30.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_31.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_32.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_01.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_02.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_03.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_04.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_05.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_06.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_07.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_08.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_09.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_10.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_11.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_12.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_13.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_14.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_15.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_16.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_17.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_18.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_19.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_20.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_21.json (deflated 54%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_22.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_23.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_24.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_25.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_26.json (deflated 51%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_27.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_28.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_29.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_30.json (deflated 53%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_31.json (deflated 52%)\n",
      "  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_32.json (deflated 53%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!zip results.zip results/*.json"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
