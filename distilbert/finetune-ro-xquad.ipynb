{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**References**\n\n[Tutorial: Working with Hugging Face Models and Datasets](https://github.com/anyuanay/medium/blob/main/src/working_huggingface/Working_with_HuggingFace_ch4_Fine_Tuning_Pretrained_Model_for_Question_Answering.ipynb)\n\n[Fine-Tuning-for-Question-Answering-SQuAD-IndoQA](https://github.com/PrasetyoWidyantoro/Fine-Tuning-for-Question-Answering-SQuAD-IndoQA/blob/master/fine-tune-squad-dataset.ipynb)","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"%pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:09.558170Z","iopub.execute_input":"2024-12-31T07:55:09.558471Z","iopub.status.idle":"2024-12-31T07:55:14.628839Z","shell.execute_reply.started":"2024-12-31T07:55:09.558428Z","shell.execute_reply":"2024-12-31T07:55:14.627914Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\nfrom tqdm.auto import tqdm\nimport evaluate\nimport numpy as np\nimport os\nimport json\n","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:14.629749Z","iopub.execute_input":"2024-12-31T07:55:14.630086Z","iopub.status.idle":"2024-12-31T07:55:30.063374Z","shell.execute_reply.started":"2024-12-31T07:55:14.630057Z","shell.execute_reply":"2024-12-31T07:55:30.062409Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Global variables","metadata":{}},{"cell_type":"code","source":"random_seed = 42\n\nkaggle = True\n\nmodel_name = \"racai/distilbert-base-romanian-cased\"\nmodel_short_name = \"distilbert-romanian\"\n\ndataset_name = (\"xquad\", \"xquad.ro\")\ndataset_short_name = \"xquad\"","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:30.064304Z","iopub.execute_input":"2024-12-31T07:55:30.064825Z","iopub.status.idle":"2024-12-31T07:55:30.068491Z","shell.execute_reply.started":"2024-12-31T07:55:30.064775Z","shell.execute_reply":"2024-12-31T07:55:30.067677Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Import model and tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n# model = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:30.070776Z","iopub.execute_input":"2024-12-31T07:55:30.071077Z","iopub.status.idle":"2024-12-31T07:55:31.211562Z","shell.execute_reply.started":"2024-12-31T07:55:30.071048Z","shell.execute_reply":"2024-12-31T07:55:31.210546Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8308d93107ff4ab9826383be13909a80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a966fcf703849e58a547196c9c6ff16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/397k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b29e2a8195e54f1b9c5dfab2a4eea87f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Split the dataset into train, validation and test","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(dataset_name[0], dataset_name[1])\n\nds = ds['validation'].train_test_split(test_size=0.2)\nds_train = ds['train']\nds_test = ds['test']\n\nds_test = ds_test.train_test_split(test_size=0.5)\nds_val = ds_test['train']\nds_test = ds_test['test']\n\nprint(len(ds_train), len(ds_val), len(ds_test))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:31.213238Z","iopub.execute_input":"2024-12-31T07:55:31.213536Z","iopub.status.idle":"2024-12-31T07:55:34.579635Z","shell.execute_reply.started":"2024-12-31T07:55:31.213501Z","shell.execute_reply":"2024-12-31T07:55:34.578732Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c18c28918d8c45c6ad3dea5dea6bc3a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/244k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"092735d9ac3840c1be92ad12f8e0182e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d375a43d1249f89eb4ffa4053e4279"}},"metadata":{}},{"name":"stdout","text":"952 119 119\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Process the dataset","metadata":{}},{"cell_type":"markdown","source":"## Train dataset","metadata":{}},{"cell_type":"code","source":"def standardize(text: str):\n    return text\n    # return text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n\ndef process_and_tokenize(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n    # Extract from the dataset and standardize where possible\n    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n    contexts = [standardize(c) for c in dataset[\"context\"]]\n    answers = dataset[\"answers\"]\n    \n    \n    inputs = tokenizer(\n        questions,\n        contexts,\n        max_length=384,\n        truncation=\"only_second\",\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n    offset_mapping = inputs[\"offset_mapping\"]\n    \n    start_pos = []\n    end_pos = []\n\n    for i, ofs in enumerate(offset_mapping):\n        # Get the sample\n        sample_i = sample_mapping[i]\n        \n        # Get the answer for the sample\n        answer = answers[sample_i]\n        \n        # Get the start and end character of the answer\n        start = answer[\"answer_start\"][0]\n        end = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        \n        # Get the sequence ids\n        seq_ids = inputs.sequence_ids(i)\n\n        # Get the start and end token positions\n        start_context = seq_ids.index(1)\n        end_context = next(j - 1 for j in range(start_context, len(seq_ids)) if seq_ids[j] != 1)\n\n        if ofs[start_context][0] > start or ofs[end_context][1] < end: # If it's impossible\n            start_pos.append(0)\n            end_pos.append(0)\n        else: # Get and append start and end position\n            start_pos.append(next((j - 1 for j in range(start_context, end_context + 1) if ofs[j][0] > start), end_context))\n            end_pos.append(next((j + 1 for j in range(end_context, start_context - 1, -1) if ofs[j][1] < end), start_context))\n            \n            # if i < len(dataset['id']) and dataset['id'][i] == '56d6f3500d65d21400198292':\n            #     print(start_context, end_context, end_pos[-1], end_pos[-1])\n\n    inputs[\"start_positions\"] = start_pos\n    inputs[\"end_positions\"] = end_pos\n        \n    inputs.pop(\"overflow_to_sample_mapping\")\n    inputs.pop(\"offset_mapping\")\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:34.580552Z","iopub.execute_input":"2024-12-31T07:55:34.580836Z","iopub.status.idle":"2024-12-31T07:55:34.588631Z","shell.execute_reply.started":"2024-12-31T07:55:34.580786Z","shell.execute_reply":"2024-12-31T07:55:34.587761Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"ds_tok_train = ds_train.map(lambda x: process_and_tokenize(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_train.column_names)\n \nprint(len(ds_tok_train))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:34.589441Z","iopub.execute_input":"2024-12-31T07:55:34.589717Z","iopub.status.idle":"2024-12-31T07:55:35.102289Z","shell.execute_reply.started":"2024-12-31T07:55:34.589685Z","shell.execute_reply":"2024-12-31T07:55:35.101330Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/952 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e8d011c71a1450e8c3f168736257810"}},"metadata":{}},{"name":"stdout","text":"998\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Validation and test datasets","metadata":{}},{"cell_type":"code","source":"def process_and_tokenize_val_test(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n    # Extract from the dataset and standardize where possible\n    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n    contexts = [standardize(c) for c in dataset[\"context\"]]\n    \n    inputs = tokenizer(\n        questions,\n        contexts,\n        max_length=384,\n        truncation=\"only_second\",\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_i = sample_mapping[i]\n        example_ids.append(dataset[\"id\"][sample_i])\n\n        seq_ids = inputs.sequence_ids(i)\n        offset = inputs[\"offset_mapping\"][i]\n        \n        for j, ofs in enumerate(offset):\n            inputs['offset_mapping'][i][j] = ofs if seq_ids[j] == 1 else None\n\n    inputs[\"example_id\"] = example_ids\n    \n    inputs.pop(\"overflow_to_sample_mapping\")\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:35.103206Z","iopub.execute_input":"2024-12-31T07:55:35.103474Z","iopub.status.idle":"2024-12-31T07:55:35.109700Z","shell.execute_reply.started":"2024-12-31T07:55:35.103450Z","shell.execute_reply":"2024-12-31T07:55:35.108774Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"ds_tok_val = ds_val.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_val.column_names)\nds_tok_test = ds_test.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_test.column_names)\n \nprint(len(ds_tok_val), len(ds_tok_test))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:35.110474Z","iopub.execute_input":"2024-12-31T07:55:35.110706Z","iopub.status.idle":"2024-12-31T07:55:35.364976Z","shell.execute_reply.started":"2024-12-31T07:55:35.110687Z","shell.execute_reply":"2024-12-31T07:55:35.364294Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64cccc5bbbf44ed2b95ef4cacd35ab13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc338a3d07b14c13bcfdd258851fb391"}},"metadata":{}},{"name":"stdout","text":"125 126\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Make metrics","metadata":{}},{"cell_type":"code","source":"%pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:35.365753Z","iopub.execute_input":"2024-12-31T07:55:35.366026Z","iopub.status.idle":"2024-12-31T07:55:40.563170Z","shell.execute_reply.started":"2024-12-31T07:55:35.365991Z","shell.execute_reply":"2024-12-31T07:55:40.562126Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=4524a1cc854a140627875b8bfc9cb9f3c15c2427492f2539852991111569b275\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"squad_metric = evaluate.load(\"squad\")\nbleu_metric = evaluate.load(\"bleu\")\nrouge_metric = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:40.564215Z","iopub.execute_input":"2024-12-31T07:55:40.564561Z","iopub.status.idle":"2024-12-31T07:55:45.629306Z","shell.execute_reply.started":"2024-12-31T07:55:40.564527Z","shell.execute_reply":"2024-12-31T07:55:45.628357Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20fdccb1c923454b8e787b5c60fabea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecd6b0364ebf4ced937e6345e881c99b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cbe9bd5bc734de9823d194c83449d1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4a66ece93b4feeb365b5e25678a2b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67fa4c1921b8459fa889dc110eb176ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a03bf3370da44d0398f730bcc4c8a4af"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def compute_metrics(start_logits: list, end_logits: list, tok: dict, dataset: Dataset, max_answer_length: int = 30) -> dict:\n    extracted_features = {}\n    \n    # Group extracted features by ids\n    for i, feature in enumerate(tok):\n        if feature[\"example_id\"] not in extracted_features:\n            extracted_features[feature[\"example_id\"]] = [i]\n        else:\n            extracted_features[feature[\"example_id\"]].append(i)\n    \n    golds_squad = [{\"id\": data[\"id\"], \"answers\": data[\"answers\"]} for data in dataset]\n    preds_squad = []\n    \n    golds_bleu = []\n    preds_bleu = []\n    \n    for data in tqdm(dataset):\n        answers = []\n\n        # Iterate over all the extracted features\n        for i in extracted_features[data[\"id\"]]:\n            start_logit = start_logits[i]\n            end_logit = end_logits[i]\n            offs = tok[i][\"offset_mapping\"]\n\n            # Get all combinations of start and end positions\n            for start_i in range(len(start_logit)):\n                for end_i in range(len(end_logit)):\n                    # Continue on wrong answers\n                    if offs[start_i] is None \\\n                        or offs[end_i] is None \\\n                        or end_i < start_i \\\n                        or end_i - start_i + 1 > max_answer_length:\n                        continue\n                    \n                    # Add text and score\n                    answer = {\n                        \"answer\": data[\"context\"][offs[start_i][0] : offs[end_i][1]],\n                        \"score\": start_logit[start_i] + end_logit[end_i]\n                    }\n                    answers.append(answer)\n                    \n        preds_squad.append(\n            {\"id\": data['id'], \"prediction_text\": max(answers, key=lambda x: x[\"score\"])['answer']} \n                if len(answers) > 0 else \n                {\"id\": data['id'], \"prediction_text\": \"\"}\n        )\n        \n        preds_bleu.append(\n            max(answers, key=lambda x: x[\"score\"])['answer']\n                if len(answers) > 0 else \n                \"\"\n        )\n        \n        golds_bleu.append(*[ans for ans in data[\"answers\"]['text']])\n        \n    return {\n        \"squad\": squad_metric.compute(predictions=preds_squad, references=golds_squad),\n        \"bleu\": bleu_metric.compute(predictions=preds_bleu, references=golds_bleu),\n        \"rouge\": rouge_metric.compute(predictions=preds_bleu, references=golds_bleu)\n    }","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:45.630140Z","iopub.execute_input":"2024-12-31T07:55:45.630366Z","iopub.status.idle":"2024-12-31T07:55:45.638650Z","shell.execute_reply.started":"2024-12-31T07:55:45.630347Z","shell.execute_reply":"2024-12-31T07:55:45.637839Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Training, evaluation and testing loop for hyperparameters","metadata":{}},{"cell_type":"code","source":"def output_metrics_to_file(metrics: dict, metric_type: str = None, lr: float = None, epoch: int = None):\n    filename = os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", f\"{model_short_name}-{dataset_short_name}-type_{metric_type}-lr_{lr}-epoch_{epoch:02}.json\" if lr is not None and epoch is not None and metric_type is not None else f\"{model_short_name}-{dataset_short_name}.json\")\n    with open(filename, \"w\") as f:\n        json.dump(metrics, f, indent=4)\n        \ndef save_model(trainer: Trainer, lr: float, epoch: int):\n    trainer.save_model(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))\n    \ndef load_model(lr: float, epoch: int) -> AutoModelForQuestionAnswering:\n    return AutoModelForQuestionAnswering.from_pretrained(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:45.641296Z","iopub.execute_input":"2024-12-31T07:55:45.641564Z","iopub.status.idle":"2024-12-31T07:55:45.661225Z","shell.execute_reply.started":"2024-12-31T07:55:45.641542Z","shell.execute_reply":"2024-12-31T07:55:45.660306Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Get maximum answer length within 2 standard deviations from the mean of the training dataset","metadata":{}},{"cell_type":"code","source":"# mean_answer_length = np.mean([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n# std_dev_answer_length = np.std([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n\n# two_std_devs_above = mean_answer_length + 2 * std_dev_answer_length","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:45.662493Z","iopub.execute_input":"2024-12-31T07:55:45.662757Z","iopub.status.idle":"2024-12-31T07:55:45.678487Z","shell.execute_reply.started":"2024-12-31T07:55:45.662735Z","shell.execute_reply":"2024-12-31T07:55:45.677576Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"all_models_eval = None\n\ndef tet_loop(lr_list: list, epochs_list: list, batch_size: int) -> None:\n    global all_models_eval\n    all_models_eval = {\"validation\": {lr:{epochs:[] for epochs in epochs_list} for lr in lr_list}, \"test\": {lr:{epochs:[] for epochs in epochs_list} for lr in lr_list}}\n    \n    for lr in lr_list:\n        for epochs in epochs_list:\n            print(f\"Training with lr={lr} and epochs={epochs}\")\n            \n            model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n            warmup_steps = int(len(ds_tok_train) / batch_size * epochs / 10)\n            \n            args = TrainingArguments(\n                output_dir=\"./results\",\n                eval_strategy=\"no\",\n                save_strategy=\"epoch\",\n                learning_rate=lr,\n                num_train_epochs=epochs,\n                weight_decay=0.01,\n                per_device_train_batch_size=batch_size, \n                report_to=\"none\",\n                save_total_limit=1,\n                warmup_steps=warmup_steps\n            )\n            trainer = Trainer(\n                model=model,\n                args=args,\n                train_dataset=ds_tok_train,\n                eval_dataset=ds_tok_val,\n                tokenizer=tokenizer\n            )\n            trainer.train()\n            \n            preds = trainer.predict(ds_tok_val)\n            start_logits, end_logits = preds[0][0], preds[0][1]\n            computed_metrics = compute_metrics(start_logits, end_logits, ds_tok_val, ds_val, 30)\n            \n            output_metrics_to_file(computed_metrics, metric_type='validation', lr=lr, epoch=epochs)\n            print(f\"Validation for lr {lr} epochs {epochs}: \")\n            # print(computed_metrics)\n            print(computed_metrics['squad'])\n            \n            all_models_eval['validation'][lr][epochs] = computed_metrics\n            \n            preds = trainer.predict(ds_tok_test)\n            start_logits2, end_logits2 = preds[0][0], preds[0][1]\n            computed_metrics = compute_metrics(start_logits2, end_logits2, ds_tok_test, ds_test, 30)\n            \n            \n            output_metrics_to_file(computed_metrics, metric_type='test', lr=lr, epoch=epochs)\n            all_models_eval['test'][lr][epochs] = computed_metrics\n            \n\n            print(f\"Test for lr {lr} epochs {epochs}: \")\n            print(computed_metrics['squad'])\n            \n            # save_model(trainer, lr, epochs)\n            \n            # Clear CUDA cache\n            try:\n                del trainer\n                del model\n                # device = cuda.get_current_device()\n                # device.reset()\n            except Exception as e:\n                print(e)\n            \n            print(f\"Finished training, validating and testing with lr={lr} and epochs={epochs}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:45.679442Z","iopub.execute_input":"2024-12-31T07:55:45.679715Z","iopub.status.idle":"2024-12-31T07:55:45.692293Z","shell.execute_reply.started":"2024-12-31T07:55:45.679692Z","shell.execute_reply":"2024-12-31T07:55:45.691547Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"tet_loop(lr_list=[1e-4, 1e-3, 1e-5], epochs_list=[4], batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-12-31T07:55:45.693006Z","iopub.execute_input":"2024-12-31T07:55:45.693197Z","iopub.status.idle":"2024-12-31T08:23:56.654669Z","shell.execute_reply.started":"2024-12-31T07:55:45.693179Z","shell.execute_reply":"2024-12-31T08:23:56.653847Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Training with lr=0.0001 and epochs=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57f3fef678654c93b9206de80a3c78b7"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at racai/distilbert-base-romanian-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [504/504 02:59, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.928100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46d2fb35c6204bb691d52651e6031421"}},"metadata":{}},{"name":"stdout","text":"Validation for lr 0.0001 epochs 8: \n{'exact_match': 16.80672268907563, 'f1': 24.333841173930153}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f8036dcfe04e8e885ce5e14fbad916"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at racai/distilbert-base-romanian-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Test for lr 0.0001 epochs 8: \n{'exact_match': 5.042016806722689, 'f1': 11.553066448024433}\nFinished training, validating and testing with lr=0.0001 and epochs=8\nTraining with lr=0.0001 and epochs=16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1008' max='1008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1008/1008 06:01, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.609600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.361800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a03a694c024a477b9ad5681b62c73540"}},"metadata":{}},{"name":"stdout","text":"Validation for lr 0.0001 epochs 16: \n{'exact_match': 12.605042016806722, 'f1': 18.26106737050619}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d8ddfd8f4dd407b85bf05b975449aa4"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at racai/distilbert-base-romanian-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Test for lr 0.0001 epochs 16: \n{'exact_match': 5.882352941176471, 'f1': 11.626966376528902}\nFinished training, validating and testing with lr=0.0001 and epochs=16\nTraining with lr=0.001 and epochs=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [504/504 03:01, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>5.850300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629bed0041e24d25b4ceaeb6c18d6998"}},"metadata":{}},{"name":"stdout","text":"Validation for lr 0.001 epochs 8: \n{'exact_match': 0.0, 'f1': 5.441955947937648}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8092e62211482dba10506f48d64186"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at racai/distilbert-base-romanian-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Test for lr 0.001 epochs 8: \n{'exact_match': 0.0, 'f1': 4.734159928144806}\nFinished training, validating and testing with lr=0.001 and epochs=8\nTraining with lr=0.001 and epochs=16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1008' max='1008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1008/1008 06:01, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>5.646800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.958600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2855a8c4fee344c9ad6e8715af37e040"}},"metadata":{}},{"name":"stdout","text":"Validation for lr 0.001 epochs 16: \n{'exact_match': 0.0, 'f1': 3.220167211269535}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d755f7a9cc744613b73870b775732ada"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at racai/distilbert-base-romanian-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Test for lr 0.001 epochs 16: \n{'exact_match': 0.8403361344537815, 'f1': 6.077122576782001}\nFinished training, validating and testing with lr=0.001 and epochs=16\nTraining with lr=1e-05 and epochs=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [504/504 03:01, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.612200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49f268605dec49168856bae89f9fe12b"}},"metadata":{}},{"name":"stdout","text":"Validation for lr 1e-05 epochs 8: \n{'exact_match': 3.361344537815126, 'f1': 10.036431831606286}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e41c0e907f24cb4a80061e7e25900c4"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at racai/distilbert-base-romanian-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Test for lr 1e-05 epochs 8: \n{'exact_match': 0.0, 'f1': 4.887395337533962}\nFinished training, validating and testing with lr=1e-05 and epochs=8\nTraining with lr=1e-05 and epochs=16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1008' max='1008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1008/1008 06:01, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.595300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.562400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c500f3cf0042248cb703100bf6e25c"}},"metadata":{}},{"name":"stdout","text":"Validation for lr 1e-05 epochs 16: \n{'exact_match': 1.680672268907563, 'f1': 6.469551210035639}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859a27523d17435e9086908a5d56b6f9"}},"metadata":{}},{"name":"stdout","text":"Test for lr 1e-05 epochs 16: \n{'exact_match': 4.201680672268908, 'f1': 7.386269753610552}\nFinished training, validating and testing with lr=1e-05 and epochs=16\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"output_metrics_to_file(all_models_eval)","metadata":{"execution":{"iopub.status.busy":"2024-12-31T08:23:56.655773Z","iopub.execute_input":"2024-12-31T08:23:56.656072Z","iopub.status.idle":"2024-12-31T08:23:56.661746Z","shell.execute_reply.started":"2024-12-31T08:23:56.656047Z","shell.execute_reply":"2024-12-31T08:23:56.660775Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!zip results.zip results/*.json","metadata":{"execution":{"iopub.status.busy":"2024-12-31T08:23:56.662901Z","iopub.execute_input":"2024-12-31T08:23:56.663223Z","iopub.status.idle":"2024-12-31T08:23:56.834671Z","shell.execute_reply.started":"2024-12-31T08:23:56.663191Z","shell.execute_reply":"2024-12-31T08:23:56.833557Z"},"trusted":true},"outputs":[{"name":"stdout","text":"  adding: results/distilbert-romanian-xquad.json (deflated 82%)\n  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_08.json (deflated 52%)\n  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_16.json (deflated 53%)\n  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_08.json (deflated 53%)\n  adding: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_16.json (deflated 52%)\n  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_08.json (deflated 54%)\n  adding: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_16.json (deflated 52%)\n  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_08.json (deflated 52%)\n  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_16.json (deflated 53%)\n  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_08.json (deflated 53%)\n  adding: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_16.json (deflated 53%)\n  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_08.json (deflated 52%)\n  adding: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_16.json (deflated 53%)\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}],"execution_count":18}]}