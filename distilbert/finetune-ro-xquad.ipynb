{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**References**\n\n[Tutorial: Working with Hugging Face Models and Datasets](https://github.com/anyuanay/medium/blob/main/src/working_huggingface/Working_with_HuggingFace_ch4_Fine_Tuning_Pretrained_Model_for_Question_Answering.ipynb)\n\n[Fine-Tuning-for-Question-Answering-SQuAD-IndoQA](https://github.com/PrasetyoWidyantoro/Fine-Tuning-for-Question-Answering-SQuAD-IndoQA/blob/master/fine-tune-squad-dataset.ipynb)","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"%pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:12:31.765696Z","iopub.execute_input":"2024-12-31T10:12:31.766114Z","iopub.status.idle":"2024-12-31T10:12:36.430705Z","shell.execute_reply.started":"2024-12-31T10:12:31.766074Z","shell.execute_reply":"2024-12-31T10:12:36.429655Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\nfrom tqdm.auto import tqdm\nimport evaluate\nimport numpy as np\nimport os\nimport json\n","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:12:36.432073Z","iopub.execute_input":"2024-12-31T10:12:36.432358Z","iopub.status.idle":"2024-12-31T10:12:50.859966Z","shell.execute_reply.started":"2024-12-31T10:12:36.432336Z","shell.execute_reply":"2024-12-31T10:12:50.859042Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Global variables","metadata":{}},{"cell_type":"code","source":"random_seed = 42\n\nkaggle = True\n\nmodel_name = \"racai/distilbert-base-romanian-cased\"\nmodel_short_name = \"distilbert-romanian\"\n\ndataset_name = (\"xquad\", \"xquad.ro\")\ndataset_short_name = \"xquad\"","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:12:50.861616Z","iopub.execute_input":"2024-12-31T10:12:50.862139Z","iopub.status.idle":"2024-12-31T10:12:50.865989Z","shell.execute_reply.started":"2024-12-31T10:12:50.862115Z","shell.execute_reply":"2024-12-31T10:12:50.865225Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Import model and tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n# model = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:12:50.867148Z","iopub.execute_input":"2024-12-31T10:12:50.867382Z","iopub.status.idle":"2024-12-31T10:12:53.202578Z","shell.execute_reply.started":"2024-12-31T10:12:50.867362Z","shell.execute_reply":"2024-12-31T10:12:53.201700Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564e43e55e894ac49bdf45de95dd6abe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9862fa2eb3104868accebb9f8162569f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/397k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1053e0ffa44cdf8ed1e2c5d38b5c8f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Split the dataset into train, validation and test","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(dataset_name[0], dataset_name[1])\n\nds = ds['validation'].train_test_split(test_size=0.2)\nds_train = ds['train']\nds_test = ds['test']\n\nds_test = ds_test.train_test_split(test_size=0.5)\nds_val = ds_test['train']\nds_test = ds_test['test']\n\nprint(len(ds_train), len(ds_val), len(ds_test))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:12:53.203366Z","iopub.execute_input":"2024-12-31T10:12:53.203664Z","iopub.status.idle":"2024-12-31T10:13:00.798877Z","shell.execute_reply.started":"2024-12-31T10:12:53.203633Z","shell.execute_reply":"2024-12-31T10:13:00.798205Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f4c33e4e62446dd96828a0fe029ecf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/244k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a069dcaa30b46618933e53638ddfab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef906fb1dd3b4b1b8be14c1964f1a078"}},"metadata":{}},{"name":"stdout","text":"952 119 119\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Process the dataset","metadata":{}},{"cell_type":"markdown","source":"## Train dataset","metadata":{}},{"cell_type":"code","source":"def standardize(text: str):\n    return text\n    # return text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n\ndef process_and_tokenize(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n    # Extract from the dataset and standardize where possible\n    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n    contexts = [standardize(c) for c in dataset[\"context\"]]\n    answers = dataset[\"answers\"]\n    \n    \n    inputs = tokenizer(\n        questions,\n        contexts,\n        max_length=384,\n        truncation=\"only_second\",\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n    offset_mapping = inputs[\"offset_mapping\"]\n    \n    start_pos = []\n    end_pos = []\n\n    for i, ofs in enumerate(offset_mapping):\n        # Get the sample\n        sample_i = sample_mapping[i]\n        \n        # Get the answer for the sample\n        answer = answers[sample_i]\n        answer = contexts[sample_i].index(answer[\"text\"][0])\n\n        \n        # Get the start and end character of the answer\n        start = answer\n        end = answer + len(answers[sample_i][\"text\"][0])\n        \n        # Get the sequence ids\n        seq_ids = inputs.sequence_ids(i)\n\n        # Get the start and end token positions\n        start_context = seq_ids.index(1)\n        end_context = next(j - 1 for j in range(start_context, len(seq_ids)) if seq_ids[j] != 1)\n\n        if ofs[start_context][0] > start or ofs[end_context][1] < end: # If it's impossible\n            start_pos.append(0)\n            end_pos.append(0)\n        else: # Get and append start and end position\n            start_pos.append(next((j - 1 for j in range(start_context, end_context + 1) if ofs[j][0] > start), end_context))\n            end_pos.append(next((j + 1 for j in range(end_context, start_context - 1, -1) if ofs[j][1] < end), start_context))\n            \n            # if i < len(dataset['id']) and dataset['id'][i] == '56d6f3500d65d21400198292':\n            #     print(start_context, end_context, end_pos[-1], end_pos[-1])\n\n    inputs[\"start_positions\"] = start_pos\n    inputs[\"end_positions\"] = end_pos\n        \n    inputs.pop(\"overflow_to_sample_mapping\")\n    inputs.pop(\"offset_mapping\")\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:00.799558Z","iopub.execute_input":"2024-12-31T10:13:00.799765Z","iopub.status.idle":"2024-12-31T10:13:00.807669Z","shell.execute_reply.started":"2024-12-31T10:13:00.799747Z","shell.execute_reply":"2024-12-31T10:13:00.807010Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"ds_tok_train = ds_train.map(lambda x: process_and_tokenize(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_train.column_names)\n \nprint(len(ds_tok_train))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:00.808566Z","iopub.execute_input":"2024-12-31T10:13:00.808867Z","iopub.status.idle":"2024-12-31T10:13:01.294649Z","shell.execute_reply.started":"2024-12-31T10:13:00.808836Z","shell.execute_reply":"2024-12-31T10:13:01.293685Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/952 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b52337d024ec4ed7b7271101a159c2c1"}},"metadata":{}},{"name":"stdout","text":"997\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Validation and test datasets","metadata":{}},{"cell_type":"code","source":"def process_and_tokenize_val_test(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n    # Extract from the dataset and standardize where possible\n    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n    contexts = [standardize(c) for c in dataset[\"context\"]]\n    \n    inputs = tokenizer(\n        questions,\n        contexts,\n        max_length=384,\n        truncation=\"only_second\",\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_i = sample_mapping[i]\n        example_ids.append(dataset[\"id\"][sample_i])\n\n        seq_ids = inputs.sequence_ids(i)\n        offset = inputs[\"offset_mapping\"][i]\n        \n        for j, ofs in enumerate(offset):\n            inputs['offset_mapping'][i][j] = ofs if seq_ids[j] == 1 else None\n\n    inputs[\"example_id\"] = example_ids\n    \n    inputs.pop(\"overflow_to_sample_mapping\")\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:01.296943Z","iopub.execute_input":"2024-12-31T10:13:01.297186Z","iopub.status.idle":"2024-12-31T10:13:01.302836Z","shell.execute_reply.started":"2024-12-31T10:13:01.297164Z","shell.execute_reply":"2024-12-31T10:13:01.302028Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"ds_tok_val = ds_val.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_val.column_names)\nds_tok_test = ds_test.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_test.column_names)\n \nprint(len(ds_tok_val), len(ds_tok_test))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:01.304058Z","iopub.execute_input":"2024-12-31T10:13:01.304331Z","iopub.status.idle":"2024-12-31T10:13:01.541593Z","shell.execute_reply.started":"2024-12-31T10:13:01.304306Z","shell.execute_reply":"2024-12-31T10:13:01.540635Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1714547c03a402ca7ec609b0f7e4081"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a7d3328ac3343969f5684bc4c46b758"}},"metadata":{}},{"name":"stdout","text":"128 124\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Make metrics","metadata":{}},{"cell_type":"code","source":"%pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:01.542499Z","iopub.execute_input":"2024-12-31T10:13:01.542746Z","iopub.status.idle":"2024-12-31T10:13:06.698590Z","shell.execute_reply.started":"2024-12-31T10:13:01.542723Z","shell.execute_reply":"2024-12-31T10:13:06.697489Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=f02b0407c4f4aec10fe8c2dc148d57b6b755e9dc5769bff805c1c1974a5349f7\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"squad_metric = evaluate.load(\"squad\")\nbleu_metric = evaluate.load(\"bleu\")\nrouge_metric = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:06.699938Z","iopub.execute_input":"2024-12-31T10:13:06.700323Z","iopub.status.idle":"2024-12-31T10:13:13.842754Z","shell.execute_reply.started":"2024-12-31T10:13:06.700288Z","shell.execute_reply":"2024-12-31T10:13:13.841824Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280c1a1cbd8146ffbfcff0f63e308fe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17573e619a1748d991187c7153fb1ce3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef8808e6fbbf4139a3eada7553e87122"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80277f9644d34cb7a18b751f3a9fa4ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd51e314c8e14c9b8d8ff9eac52878f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c593cb16a6f44159ae5cfa90e2a9bb4"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def compute_metrics(start_logits: list, end_logits: list, tok: dict, dataset: Dataset, max_answer_length: int = 30) -> dict:\n    extracted_features = {}\n    \n    # Group extracted features by ids\n    for i, feature in enumerate(tok):\n        if feature[\"example_id\"] not in extracted_features:\n            extracted_features[feature[\"example_id\"]] = [i]\n        else:\n            extracted_features[feature[\"example_id\"]].append(i)\n    \n    golds_squad = [{\"id\": data[\"id\"], \"answers\": data[\"answers\"]} for data in dataset]\n    preds_squad = []\n    \n    golds_bleu = []\n    preds_bleu = []\n    \n    for data in tqdm(dataset):\n        answers = []\n\n        # Iterate over all the extracted features\n        for i in extracted_features[data[\"id\"]]:\n            start_logit = start_logits[i]\n            end_logit = end_logits[i]\n            offs = tok[i][\"offset_mapping\"]\n\n            # Get all combinations of start and end positions\n            for start_i in range(len(start_logit)):\n                for end_i in range(len(end_logit)):\n                    # Continue on wrong answers\n                    if offs[start_i] is None \\\n                        or offs[end_i] is None \\\n                        or end_i < start_i \\\n                        or end_i - start_i + 1 > max_answer_length:\n                        continue\n                    \n                    # Add text and score\n                    answer = {\n                        \"answer\": data[\"context\"][offs[start_i][0] : offs[end_i][1]],\n                        \"score\": start_logit[start_i] + end_logit[end_i]\n                    }\n                    answers.append(answer)\n                    \n        preds_squad.append(\n            {\"id\": data['id'], \"prediction_text\": max(answers, key=lambda x: x[\"score\"])['answer']} \n                if len(answers) > 0 else \n                {\"id\": data['id'], \"prediction_text\": \"\"}\n        )\n        \n        preds_bleu.append(\n            max(answers, key=lambda x: x[\"score\"])['answer']\n                if len(answers) > 0 else \n                \"\"\n        )\n        \n        golds_bleu.append(*[ans for ans in data[\"answers\"]['text']])\n        \n    return {\n        \"squad\": squad_metric.compute(predictions=preds_squad, references=golds_squad),\n        \"bleu\": bleu_metric.compute(predictions=preds_bleu, references=golds_bleu),\n        \"rouge\": rouge_metric.compute(predictions=preds_bleu, references=golds_bleu)\n    }","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:13.843660Z","iopub.execute_input":"2024-12-31T10:13:13.843955Z","iopub.status.idle":"2024-12-31T10:13:13.852059Z","shell.execute_reply.started":"2024-12-31T10:13:13.843922Z","shell.execute_reply":"2024-12-31T10:13:13.851149Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Training, evaluation and testing loop for hyperparameters","metadata":{}},{"cell_type":"code","source":"def output_metrics_to_file(metrics: dict, metric_type: str = None, lr: float = None, epoch: int = None):\n    filename = os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", f\"{model_short_name}-{dataset_short_name}-type_{metric_type}-lr_{lr}-epoch_{epoch:02}.json\" if lr is not None and epoch is not None and metric_type is not None else f\"{model_short_name}-{dataset_short_name}.json\")\n    with open(filename, \"w\") as f:\n        json.dump(metrics, f, indent=4)\n        \ndef save_model(trainer: Trainer, lr: float, epoch: int):\n    trainer.save_model(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))\n    \ndef load_model(lr: float, epoch: int) -> AutoModelForQuestionAnswering:\n    return AutoModelForQuestionAnswering.from_pretrained(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:13.852875Z","iopub.execute_input":"2024-12-31T10:13:13.853160Z","iopub.status.idle":"2024-12-31T10:13:13.872457Z","shell.execute_reply.started":"2024-12-31T10:13:13.853130Z","shell.execute_reply":"2024-12-31T10:13:13.871823Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Get maximum answer length within 2 standard deviations from the mean of the training dataset","metadata":{}},{"cell_type":"code","source":"# mean_answer_length = np.mean([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n# std_dev_answer_length = np.std([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n\n# two_std_devs_above = mean_answer_length + 2 * std_dev_answer_length","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:13.873131Z","iopub.execute_input":"2024-12-31T10:13:13.873344Z","iopub.status.idle":"2024-12-31T10:13:13.889165Z","shell.execute_reply.started":"2024-12-31T10:13:13.873325Z","shell.execute_reply":"2024-12-31T10:13:13.888308Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"all_models_eval = None\n\ndef tet_loop(lr_list: list, epochs_list: list, batch_size: int) -> None:\n    global all_models_eval\n    all_models_eval = {\"validation\": {lr:{epochs:[] for epochs in epochs_list} for lr in lr_list}, \"test\": {lr:{epochs:[] for epochs in epochs_list} for lr in lr_list}}\n    \n    for lr in lr_list:\n        for epochs in epochs_list:\n            print(f\"Training with lr={lr} and epochs={epochs}\")\n            \n            model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n            warmup_steps = int(len(ds_tok_train) / batch_size * epochs / 10)\n            \n            args = TrainingArguments(\n                output_dir=\"./results\",\n                eval_strategy=\"no\",\n                save_strategy=\"epoch\",\n                learning_rate=lr,\n                num_train_epochs=epochs,\n                weight_decay=0.01,\n                per_device_train_batch_size=batch_size, \n                report_to=\"none\",\n                save_total_limit=1,\n                warmup_steps=warmup_steps\n            )\n            trainer = Trainer(\n                model=model,\n                args=args,\n                train_dataset=ds_tok_train,\n                eval_dataset=ds_tok_val,\n                tokenizer=tokenizer\n            )\n            trainer.train()\n            \n            preds = trainer.predict(ds_tok_val)\n            start_logits, end_logits = preds[0][0], preds[0][1]\n            computed_metrics = compute_metrics(start_logits, end_logits, ds_tok_val, ds_val, 30)\n            \n            output_metrics_to_file(computed_metrics, metric_type='validation', lr=lr, epoch=epochs)\n            print(f\"Validation for lr {lr} epochs {epochs}: \")\n            # print(computed_metrics)\n            print(computed_metrics['squad'])\n            \n            all_models_eval['validation'][lr][epochs] = computed_metrics\n            \n            preds = trainer.predict(ds_tok_test)\n            start_logits2, end_logits2 = preds[0][0], preds[0][1]\n            computed_metrics = compute_metrics(start_logits2, end_logits2, ds_tok_test, ds_test, 30)\n            \n            \n            output_metrics_to_file(computed_metrics, metric_type='test', lr=lr, epoch=epochs)\n            all_models_eval['test'][lr][epochs] = computed_metrics\n            \n\n            print(f\"Test for lr {lr} epochs {epochs}: \")\n            print(computed_metrics['squad'])\n            \n            # save_model(trainer, lr, epochs)\n            \n            # Clear CUDA cache\n            try:\n                del trainer\n                del model\n                # device = cuda.get_current_device()\n                # device.reset()\n            except Exception as e:\n                print(e)\n            \n            print(f\"Finished training, validating and testing with lr={lr} and epochs={epochs}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:13:13.889946Z","iopub.execute_input":"2024-12-31T10:13:13.890260Z","iopub.status.idle":"2024-12-31T10:13:13.901535Z","shell.execute_reply.started":"2024-12-31T10:13:13.890211Z","shell.execute_reply":"2024-12-31T10:13:13.900764Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"tet_loop(lr_list=[1e-4], epochs_list=[32], batch_size=16)\n# tet_loop(lr_list=[1e-4], epochs_list=[8], batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:41:59.568389Z","iopub.execute_input":"2024-12-31T10:41:59.568714Z","iopub.status.idle":"2024-12-31T10:54:02.790463Z","shell.execute_reply.started":"2024-12-31T10:41:59.568688Z","shell.execute_reply":"2024-12-31T10:54:02.789691Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Training with lr=0.0001 and epochs=32\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at racai/distilbert-base-romanian-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2016' max='2016' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2016/2016 11:52, Epoch 32/32]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>3.054900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.525600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.182300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.097800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f54447e2b6f45508ab72bc60f0d018b"}},"metadata":{}},{"name":"stdout","text":"Validation for lr 0.0001 epochs 32: \n{'exact_match': 9.243697478991596, 'f1': 14.276203843248055}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/119 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9a13c7a1ac148bb924a90eb6fc157ce"}},"metadata":{}},{"name":"stdout","text":"Test for lr 0.0001 epochs 32: \n{'exact_match': 13.445378151260504, 'f1': 19.299146014335133}\nFinished training, validating and testing with lr=0.0001 and epochs=32\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"output_metrics_to_file(all_models_eval)","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:54:13.018254Z","iopub.execute_input":"2024-12-31T10:54:13.018588Z","iopub.status.idle":"2024-12-31T10:54:13.023559Z","shell.execute_reply.started":"2024-12-31T10:54:13.018558Z","shell.execute_reply":"2024-12-31T10:54:13.022758Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"!zip results.zip results/*.json","metadata":{"execution":{"iopub.status.busy":"2024-12-31T10:54:11.872324Z","iopub.execute_input":"2024-12-31T10:54:11.872649Z","iopub.status.idle":"2024-12-31T10:54:12.029603Z","shell.execute_reply.started":"2024-12-31T10:54:11.872623Z","shell.execute_reply":"2024-12-31T10:54:12.028632Z"},"trusted":true},"outputs":[{"name":"stdout","text":"updating: results/distilbert-romanian-xquad.json (deflated 82%)\nupdating: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_08.json (deflated 53%)\nupdating: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_16.json (deflated 53%)\nupdating: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_08.json (deflated 52%)\nupdating: results/distilbert-romanian-xquad-type_test-lr_0.001-epoch_16.json (deflated 53%)\nupdating: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_08.json (deflated 53%)\nupdating: results/distilbert-romanian-xquad-type_test-lr_1e-05-epoch_16.json (deflated 52%)\nupdating: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_08.json (deflated 52%)\nupdating: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_16.json (deflated 52%)\nupdating: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_08.json (deflated 54%)\nupdating: results/distilbert-romanian-xquad-type_validation-lr_0.001-epoch_16.json (deflated 52%)\nupdating: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_08.json (deflated 54%)\nupdating: results/distilbert-romanian-xquad-type_validation-lr_1e-05-epoch_16.json (deflated 52%)\n  adding: results/distilbert-romanian-xquad-type_test-lr_0.0001-epoch_32.json (deflated 53%)\n  adding: results/distilbert-romanian-xquad-type_validation-lr_0.0001-epoch_32.json (deflated 53%)\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}],"execution_count":20}]}