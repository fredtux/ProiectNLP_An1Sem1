{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "[Tutorial: Working with Hugging Face Models and Datasets](https://github.com/anyuanay/medium/blob/main/src/working_huggingface/Working_with_HuggingFace_ch4_Fine_Tuning_Pretrained_Model_for_Question_Answering.ipynb)\n",
    "\n",
    "[Fine-Tuning-for-Question-Answering-SQuAD-IndoQA](https://github.com/PrasetyoWidyantoro/Fine-Tuning-for-Question-Answering-SQuAD-IndoQA/blob/master/fine-tune-squad-dataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/kaggle/input/roitdaug/ds_roitd_augumented.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/roitdaug/ds_roitd_augumented.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.48.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (19.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "kaggle = False\n",
    "\n",
    "model_name = \"readerbench/RoGPT2-medium\"\n",
    "model_short_name = \"roGPT2\"\n",
    "\n",
    "dataset_name = (\"xquad\", \"xquad.ro\")\n",
    "dataset_short_name = \"roitd_noaug\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7727886a981d4ba5a7b1f7ff0265c821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/563 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4340c1ab81ed452990dc52b8149aad08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/869 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bce9031b59c4e50a8e2bc031a5a50e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/985k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c750ae234214f7380ee6dd832ec3dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/542k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed82b1fdfa2e405f9ab30df701a1865a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 119 119\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(dataset_name[0], dataset_name[1])\n",
    "\n",
    "ds = ds['validation'].train_test_split(test_size=0.2)\n",
    "ds_train = ds['train']\n",
    "ds_test = ds['test']\n",
    "\n",
    "ds_test = ds_test.train_test_split(test_size=0.5)\n",
    "ds_val = ds_test['train']\n",
    "ds_test = ds_test['test']\n",
    "\n",
    "print(len(ds_train), len(ds_val), len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'answers'],\n",
       "    num_rows: 4417\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/kaggle/input/roitdaug/ds_roitd_augumented.json' if kaggle else 'ds_roitd_augumented.json', 'r') as f:\n",
    "    ds_roitd = json.load(f) \n",
    "\n",
    "ds_train = Dataset.from_pandas(pd.DataFrame(ds_roitd))\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(text: str):\n",
    "    return text\n",
    "    # return text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n",
    "\n",
    "def process_and_tokenize(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n",
    "    # Extract from the dataset and standardize where possible\n",
    "    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n",
    "    contexts = [standardize(c) for c in dataset[\"context\"]]\n",
    "    answers = dataset[\"answers\"]\n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n",
    "    offset_mapping = inputs[\"offset_mapping\"]\n",
    "    \n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "\n",
    "    for i, ofs in enumerate(offset_mapping):\n",
    "        # Get the sample\n",
    "        sample_i = sample_mapping[i]\n",
    "        \n",
    "        # Get the answer for the sample\n",
    "        answer = answers[sample_i]\n",
    "        \n",
    "        # Get the start and end character of the answer\n",
    "        start = answer[\"answer_start\"][0]\n",
    "        end = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        \n",
    "        # Get the sequence ids\n",
    "        seq_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Get the start and end token positions\n",
    "        start_context = seq_ids.index(1)\n",
    "        end_context = next((j - 1 for j in range(start_context, len(seq_ids)) if seq_ids[j] != 1),len(seq_ids) - 1)\n",
    "\n",
    "        if ofs[start_context][0] > start or ofs[end_context][1] < end: # If it's impossible\n",
    "            start_pos.append(0)\n",
    "            end_pos.append(0)\n",
    "        else: # Get and append start and end position\n",
    "            start_pos.append(next((j - 1 for j in range(start_context, end_context + 1) if ofs[j][0] > start), end_context))\n",
    "            end_pos.append(next((j + 1 for j in range(end_context, start_context - 1, -1) if ofs[j][1] < end), start_context))\n",
    "            \n",
    "            # if i < len(dataset['id']) and dataset['id'][i] == '56d6f3500d65d21400198292':\n",
    "            #     print(start_context, end_context, end_pos[-1], end_pos[-1])\n",
    "\n",
    "    inputs[\"start_positions\"] = start_pos\n",
    "    inputs[\"end_positions\"] = end_pos\n",
    "        \n",
    "    inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    inputs.pop(\"offset_mapping\")\n",
    "    \n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fac3c99ad14befa75968ef986f50ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4419\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "ds_tok_train = ds_train.map(lambda x: process_and_tokenize(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_train.column_names)\n",
    " \n",
    "print(len(ds_tok_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_tokenize_val_test(dataset: Dataset, tokenizer: AutoTokenizer) -> dict:\n",
    "    # Extract from the dataset and standardize where possible\n",
    "    questions = [standardize(q).strip() for q in dataset[\"question\"]]\n",
    "    contexts = [standardize(c) for c in dataset[\"context\"]]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = inputs[\"overflow_to_sample_mapping\"]\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_i = sample_mapping[i]\n",
    "        example_ids.append(dataset[\"id\"][sample_i])\n",
    "\n",
    "        seq_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        \n",
    "        for j, ofs in enumerate(offset):\n",
    "            inputs['offset_mapping'][i][j] = ofs if seq_ids[j] == 1 else None\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    \n",
    "    inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92283a2a22546ea9834672ae2741508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4433d2586a68439c8d6ac3babcd54857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 130\n"
     ]
    }
   ],
   "source": [
    "ds_tok_val = ds_val.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_val.column_names)\n",
    "ds_tok_test = ds_test.map(lambda x: process_and_tokenize_val_test(dataset=x, tokenizer=tokenizer), batched=True, batch_size=64, remove_columns=ds_test.column_names)\n",
    " \n",
    "print(len(ds_tok_val), len(ds_tok_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.3)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (4.67.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_metric = evaluate.load(\"squad\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(start_logits: list, end_logits: list, tok: dict, dataset: Dataset, max_answer_length: int = 30, eval_answer: SentenceTransformer = SentenceTransformer(\"BlackKakapo/stsb-xlm-r-multilingual-ro\")) -> dict:\n",
    "    extracted_features = {}\n",
    "    \n",
    "    # Group extracted features by ids\n",
    "    for i, feature in enumerate(tok):\n",
    "        if feature[\"example_id\"] not in extracted_features:\n",
    "            extracted_features[feature[\"example_id\"]] = [i]\n",
    "        else:\n",
    "            extracted_features[feature[\"example_id\"]].append(i)\n",
    "    \n",
    "    golds_squad = [{\"id\": data[\"id\"], \"answers\": data[\"answers\"]} for data in dataset]\n",
    "    preds_squad = []\n",
    "    \n",
    "    golds_bleu = []\n",
    "    preds_bleu = []\n",
    "    \n",
    "    for data in tqdm(dataset):\n",
    "        answers = []\n",
    "\n",
    "        # Iterate over all the extracted features\n",
    "        for i in extracted_features[data[\"id\"]]:\n",
    "            start_logit = start_logits[i]\n",
    "            end_logit = end_logits[i]\n",
    "            offs = tok[i][\"offset_mapping\"]\n",
    "\n",
    "            # Get all combinations of start and end positions\n",
    "            for start_i in range(len(start_logit)):\n",
    "                for end_i in range(len(end_logit)):\n",
    "                    # Continue on wrong answers\n",
    "                    if offs[start_i] is None \\\n",
    "                        or offs[end_i] is None \\\n",
    "                        or end_i < start_i \\\n",
    "                        or end_i - start_i + 1 > max_answer_length:\n",
    "                        continue\n",
    "                    \n",
    "                    # Add text and score\n",
    "                    answer = {\n",
    "                        \"answer\": data[\"context\"][offs[start_i][0] : offs[end_i][1]],\n",
    "                        \"score\": start_logit[start_i] + end_logit[end_i]\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "                    \n",
    "        preds_squad.append(\n",
    "            {\"id\": data['id'], \"prediction_text\": max(answers, key=lambda x: x[\"score\"])['answer']} \n",
    "                if len(answers) > 0 else \n",
    "                {\"id\": data['id'], \"prediction_text\": \"\"}\n",
    "        )\n",
    "        \n",
    "        preds_bleu.append(\n",
    "            max(answers, key=lambda x: x[\"score\"])['answer']\n",
    "                if len(answers) > 0 else \n",
    "                \"\"\n",
    "        )\n",
    "        \n",
    "        max_i = 0\n",
    "        max_len = len(data[\"answers\"][\"text\"][max_i])\n",
    "        for i in range(1, len(data[\"answers\"]['text'])):\n",
    "            if len(data[\"answers\"][\"text\"][i]) > max_len:\n",
    "                max_len = len(data[\"answers\"][\"text\"][i])\n",
    "                max_i = i\n",
    "        \n",
    "        golds_bleu.append(data[\"answers\"]['text'][max_i])\n",
    "        \n",
    "    return {\n",
    "        \"squad\": squad_metric.compute(predictions=preds_squad, references=golds_squad),\n",
    "        \"bleu\": bleu_metric.compute(predictions=preds_bleu, references=golds_bleu),\n",
    "        \"rouge\": rouge_metric.compute(predictions=preds_bleu, references=golds_bleu),\n",
    "        \"semantic_similarity\": util.pytorch_cos_sim(eval_answer.encode(preds_bleu, convert_to_tensor=True), eval_answer.encode(golds_bleu, convert_to_tensor=True)).mean().item() * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, evaluation and testing loop for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_metrics_to_file(metrics: dict, metric_type: str = None, lr: float = None, epoch: int = None):\n",
    "    filename = os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", f\"{model_short_name}-{dataset_short_name}-type_{metric_type}-lr_{lr}-epoch_{epoch:02}.json\" if lr is not None and epoch is not None and metric_type is not None else f\"{model_short_name}-{dataset_short_name}.json\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "        \n",
    "def save_model(trainer: Trainer, lr: float, epoch: int):\n",
    "    trainer.save_model(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))\n",
    "    \n",
    "def load_model(lr: float, epoch: int) -> AutoModelForQuestionAnswering:\n",
    "    return AutoModelForQuestionAnswering.from_pretrained(os.path.join(\"/kaggle/working/\" if kaggle else \".\", \"results\", \"models\", f\"{model_short_name}-{dataset_short_name}-{lr}-{epoch}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get maximum answer length within 2 standard deviations from the mean of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_answer_length = np.mean([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n",
    "# std_dev_answer_length = np.std([len(a[\"text\"][0]) for a in ds_train[\"answers\"]])\n",
    "\n",
    "# two_std_devs_above = mean_answer_length + 2 * std_dev_answer_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_eval = None\n",
    "\n",
    "def tet_loop(lr_list: list, epochs: int, batch_size: int) -> None:\n",
    "    global all_models_eval\n",
    "    all_models_eval = {\"validation\": {lr:{epoch:[] for epoch in range(1, epochs + 1)} for lr in lr_list}, \"test\": {lr:{epoch:[] for epoch in range(1, epochs + 1)} for lr in lr_list}}\n",
    "    \n",
    "    eval_answer = SentenceTransformer(\"BlackKakapo/stsb-xlm-r-multilingual-ro\")\n",
    "    \n",
    "    for lr in lr_list:\n",
    "        model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "        warmup_steps = int(len(ds_tok_train) / batch_size * 1 / 10)\n",
    "        args = TrainingArguments(\n",
    "                output_dir=\"./results\",\n",
    "                eval_strategy=\"no\",\n",
    "                save_strategy=\"epoch\",\n",
    "                learning_rate=lr,\n",
    "                num_train_epochs=1,\n",
    "                weight_decay=0.01,\n",
    "                per_device_train_batch_size=batch_size, \n",
    "                report_to=\"none\",\n",
    "                save_total_limit=1,\n",
    "                warmup_steps=warmup_steps\n",
    "            )\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=ds_tok_train,\n",
    "            eval_dataset=ds_tok_val,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            print(f\"Training with lr={lr} and epoch={epoch}\")\n",
    "            \n",
    "            trainer.train()\n",
    "            \n",
    "            preds = trainer.predict(ds_tok_val)\n",
    "            start_logits, end_logits = preds[0][0], preds[0][1]\n",
    "            computed_metrics = compute_metrics(start_logits, end_logits, ds_tok_val, ds_val, 30, eval_answer)\n",
    "            \n",
    "            # output_metrics_to_file(computed_metrics, metric_type='validation', lr=lr, epoch=epoch)\n",
    "            print(f\"Validation for lr {lr} epoch {epoch}: \")\n",
    "            # print(computed_metrics)\n",
    "            print(computed_metrics['squad'])\n",
    "            print(computed_metrics['semantic_similarity'])\n",
    "            \n",
    "            all_models_eval['validation'][lr][epoch] = computed_metrics\n",
    "            \n",
    "            preds = trainer.predict(ds_tok_test)\n",
    "            start_logits2, end_logits2 = preds[0][0], preds[0][1]\n",
    "            computed_metrics = compute_metrics(start_logits2, end_logits2, ds_tok_test, ds_test, 30, eval_answer)\n",
    "            \n",
    "            \n",
    "            # output_metrics_to_file(computed_metrics, metric_type='test', lr=lr, epoch=epoch)\n",
    "            all_models_eval['test'][lr][epoch] = computed_metrics\n",
    "            \n",
    "\n",
    "            print(f\"Test for lr {lr} epoch {epoch}: \")\n",
    "            print(computed_metrics['squad'])\n",
    "            print(computed_metrics['semantic_similarity'])\n",
    "            \n",
    "            # save_model(trainer, lr, epoch)\n",
    "            \n",
    "        try:\n",
    "            del trainer\n",
    "            del model\n",
    "            # device = cuda.get_current_device()\n",
    "            # device.reset()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            print(f\"Finished training, validating and testing with lr={lr} and epochs={epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885d3601d078480aa5fe385eb460ff85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at readerbench/RoGPT2-medium and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_935/2784409545.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with lr=0.0001 and epoch=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='553' max='553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [553/553 05:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.842400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b912176edafd4499a87dd01d411d8ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b7ee067e8143f391da60318529b70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epoch 1: \n",
      "{'exact_match': 8.403361344537815, 'f1': 26.44986448732839}\n",
      "13.056686520576477\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f758e2293c4149f6866f86b6ed4c2a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epoch 1: \n",
      "{'exact_match': 5.882352941176471, 'f1': 25.268855624675986}\n",
      "12.99872100353241\n",
      "Training with lr=0.0001 and epoch=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='553' max='553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [553/553 05:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.699400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6bfac1f56e416daf7aa8b5401f4ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epoch 2: \n",
      "{'exact_match': 8.403361344537815, 'f1': 27.892393599160506}\n",
      "12.964668869972229\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326a994c97da4276a4824d3647b70e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epoch 2: \n",
      "{'exact_match': 6.722689075630252, 'f1': 27.407142276974724}\n",
      "13.318152725696564\n",
      "Training with lr=0.0001 and epoch=3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='553' max='553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [553/553 05:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.024700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20feb8e283784a6e88f6e74e2905d306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epoch 3: \n",
      "{'exact_match': 7.563025210084033, 'f1': 30.20010515674849}\n",
      "13.843239843845367\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e111628e4f234029ae92cd03faf4b841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epoch 3: \n",
      "{'exact_match': 5.042016806722689, 'f1': 26.809481730886432}\n",
      "13.321208953857422\n",
      "Training with lr=0.0001 and epoch=4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='553' max='553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [553/553 05:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.712200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a921261c2c16465ebc9fab24e7bda9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epoch 4: \n",
      "{'exact_match': 11.764705882352942, 'f1': 30.21672711653719}\n",
      "13.727889955043793\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df665251d2264058a4e9f460c990cdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epoch 4: \n",
      "{'exact_match': 5.042016806722689, 'f1': 27.49129876189825}\n",
      "13.65220993757248\n",
      "Training with lr=0.0001 and epoch=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='553' max='553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [553/553 05:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.534900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0ef0d48ad74899a4b508e0cb5987a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for lr 0.0001 epoch 5: \n",
      "{'exact_match': 10.084033613445378, 'f1': 30.26208376485113}\n",
      "13.655310869216919\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b885dfca974b948b28ac13a4a57cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for lr 0.0001 epoch 5: \n",
      "{'exact_match': 7.563025210084033, 'f1': 27.327106396099584}\n",
      "13.62074762582779\n",
      "Training with lr=0.0001 and epoch=6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='148' max='553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [148/553 01:25 < 03:56, 1.72 it/s, Epoch 0.27/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tet_loop(lr_list=[1e-4, 1e-3, 1e-5], epochs=8, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metrics_to_file(all_models_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip results_ml_noaug.zip results/*.json"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6429731,
     "sourceId": 10379574,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
